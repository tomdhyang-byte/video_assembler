# ðŸ§‘â€ðŸ’» AutoVideoMaker ç¨‹å¼ç¢¼æž¶æ§‹æŒ‡å—

> å°ˆç‚ºå·¥ç¨‹å¸«è¨­è¨ˆçš„å¿«é€Ÿä¸Šæ‰‹æ–‡ä»¶

## å°ˆæ¡ˆçµæ§‹

```
AutoVideoMaker/
â”œâ”€â”€ batch_video_assembler.py   # ðŸŽ¬ å½±ç‰‡åˆæˆå…¥å£ (CLI)
â”œâ”€â”€ generate_subtitles.py      # ðŸŽ™ï¸ å­—å¹•ç”Ÿæˆä¸»ç¨‹å¼
â”œâ”€â”€ config.py                  # âš™ï¸ å…±ç”¨è¨­å®šåƒæ•¸
â””â”€â”€ engines/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ ffmpeg_engine.py       # ðŸ”§ FFmpeg æ ¸å¿ƒå¼•æ“Ž
```

---

## æ¨¡çµ„è·è²¬

| æª”æ¡ˆ | è·è²¬ | é—œéµä¾è³´ |
|:---|:---|:---|
| `generate_subtitles.py` | Whisper èªžéŸ³è¾¨è­˜ â†’ DTW å°é½Š â†’ GPT æ–·å¥ â†’ SRT è¼¸å‡º | OpenAI API, OpenCC |
| `batch_video_assembler.py` | CLI å…¥å£ï¼Œè·¯å¾‘é©—è­‰ï¼Œå‘¼å« ffmpeg_engine | config, engines |
| `config.py` | å½±ç‰‡è¦æ ¼ã€å­—å¹•æ¨£å¼ã€Avatar ä½ç½®ç­‰å…±ç”¨å¸¸æ•¸ | - |
| `engines/ffmpeg_engine.py` | éŸ³è¨Šå°é½Šã€å¹³è¡Œæ¸²æŸ“ã€æœ€çµ‚åˆæˆ | numpy, scipy, FFmpeg |

---

## è³‡æ–™æµç¨‹åœ–

```mermaid
flowchart LR
    subgraph è¼¸å…¥
        A[avatar_full.mp4]
        B[script.txt]
        C[*.mp3 åˆ‡ç‰‡]
        D[*.png ç°¡å ±]
    end

    subgraph å­—å¹•ç”Ÿæˆ
        GS[generate_subtitles.py]
        A --> GS
        B --> GS
        GS --> SRT[full_subtitle.srt]
    end

    subgraph å½±ç‰‡åˆæˆ
        BVA[batch_video_assembler.py]
        ENG[ffmpeg_engine.py]
        A --> BVA
        C --> BVA
        D --> BVA
        SRT --> BVA
        BVA --> ENG
    end

    ENG --> OUT[å®Œæˆå½±ç‰‡.mp4]
```

---

## æ ¸å¿ƒå‡½æ•¸é€ŸæŸ¥

### `generate_subtitles.py`

```python
step1_transcribe_whisper(audio_path)     # Whisper API å–å¾—å­—ç´šæ™‚é–“æˆ³
step2_force_alignment(whisper_ts, script) # DTW å°é½Šä¿®æ­£éŒ¯å­—
step3_segment_text(transcript, client)    # GPT-4o-mini æ™ºæ…§æ–·å¥
step4_align_timestamps(lines, chars)      # çµ„åˆæ™‚é–“è»¸ â†’ SRT
```

### `engines/ffmpeg_engine.py`

```python
find_audio_offset(main, segment, sr)      # FFT éŸ³è¨ŠæŒ‡ç´‹å®šä½
create_segment_videos(pairs, temp, dur)   # å¹³è¡Œæ¸²æŸ“ç‰‡æ®µ (8 threads)
concat_segments(segments, output)         # ä¸²æŽ¥ç‰‡æ®µ
create_avatar_overlay_video(avatar, dur)  # åœ“å½¢é®ç½© Avatar
composite_final_video(base, avatar, ...)  # æœ€çµ‚åˆæˆ
run(folder_path, output_path)             # å¼•æ“Žå…¥å£
```

### `config.py` è¨­å®šé¡žåˆ¥

```python
VideoConfig       # WIDTH=1920, HEIGHT=1080, FPS=24
SubtitleConfig    # FONT_SIZE=96, COLOR="yellow"
AvatarConfig      # CROP_X/Y, SCALE_RATIO=0.12
ProcessingConfig  # MAX_WORKERS=8
FileNames         # SUBTITLE_FILE, AVATAR_FILE...
OutputConfig      # OUTPUT_DIR = ~/Desktop
```

---

## é—œéµæŠ€è¡“å¯¦ä½œ

### 1. Force Alignment (DTW)
**ä½ç½®**: `generate_subtitles.py` â†’ `step2_force_alignment()`

å°‡ Whisper è¾¨è­˜çµæžœèˆ‡æ­£ç¢ºé€å­—ç¨¿å°é½Šï¼Œä¿®æ­£éŒ¯å­—åŒæ™‚ä¿ç•™ç²¾ç¢ºæ™‚é–“æˆ³ã€‚

### 2. éŸ³è¨ŠæŒ‡ç´‹å°é½Š (FFT Cross-Correlation)
**ä½ç½®**: `ffmpeg_engine.py` â†’ `find_audio_offset()`

ç”¨ FFT æ‰¾å‡ºæ¯å€‹ MP3 åˆ‡ç‰‡åœ¨ç¸½éŸ³è»Œä¸­çš„ç²¾ç¢ºä½ç½®ï¼Œé¿å…æ™‚é–“ç´¯ç©èª¤å·®ã€‚

### 3. å¹€ç´šç²¾ç¢ºè¨ˆç®—
**ä½ç½®**: `ffmpeg_engine.py` â†’ `create_segment_videos()`

æ‰€æœ‰æ™‚é–“è½‰æ›ç‚ºå¹€æ•¸è¨ˆç®—ï¼Œç¢ºä¿ `Î£(ç‰‡æ®µå¹€æ•¸) == ç¸½å½±ç‰‡å¹€æ•¸`ã€‚

### 4. å¹³è¡Œæ¸²æŸ“
**ä½ç½®**: `ffmpeg_engine.py` â†’ `create_segment_videos()`

ä½¿ç”¨ `ThreadPoolExecutor(max_workers=8)` åŒæ™‚æ¸²æŸ“å¤šå€‹ç‰‡æ®µã€‚

---

## å¿«é€Ÿé–‹å§‹

```bash
# 1. ç”Ÿæˆå­—å¹•
python generate_subtitles.py

# 2. åˆæˆå½±ç‰‡
python batch_video_assembler.py /path/to/ç´ æè³‡æ–™å¤¾
```

### ç´ æè³‡æ–™å¤¾çµæ§‹

```
ç´ æè³‡æ–™å¤¾/
â”œâ”€â”€ avatar_full.mp4    # å¿…é ˆï¼šä¸»æ’­å½±ç‰‡ (éŸ³è¨Šä¾†æº)
â”œâ”€â”€ script.txt         # å­—å¹•ç”Ÿæˆç”¨ï¼šé€å­—ç¨¿
â”œâ”€â”€ 1.mp3, 2.mp3...    # åˆ‡ç‰‡èªžéŸ³
â”œâ”€â”€ 1.png, 2.png...    # å°æ‡‰ç°¡å ±åœ–ç‰‡
â””â”€â”€ full_subtitle.srt  # ç”Ÿæˆçš„å­—å¹•æª”
```

---

## ä¾è³´é—œä¿‚

```mermaid
graph TD
    BVA[batch_video_assembler.py] --> CFG[config.py]
    BVA --> ENG[engines/ffmpeg_engine.py]
    ENG --> CFG
    GS[generate_subtitles.py] --> CFG
    
    ENG -.-> FFMPEG[FFmpeg CLI]
    ENG -.-> NUMPY[numpy/scipy]
    GS -.-> OPENAI[OpenAI API]
    GS -.-> OPENCC[OpenCC]
```
