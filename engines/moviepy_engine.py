#!/usr/bin/env python3
"""
MoviePy å¼•æ“ - ä½¿ç”¨ MoviePy åº«é€²è¡Œå½±ç‰‡åˆæˆ
ç©©å®šä½†è¼ƒæ…¢ï¼Œä½œç‚º FFmpeg å¼•æ“çš„å‚™ç”¨æ–¹æ¡ˆ
"""

import os
import subprocess
import tempfile
import re
from pathlib import Path

import numpy as np
from PIL import Image, ImageDraw

from moviepy import (
    ImageClip,
    AudioFileClip,
    VideoFileClip,
    TextClip,
    concatenate_videoclips,
    CompositeVideoClip
)

from config import (
    VideoConfig,
    SubtitleConfig,
    AvatarConfig,
    FileNames,
    OutputConfig,
    IGNORE_FILES
)


# ============================================================
# å·¥å…·å‡½æ•¸
# ============================================================
def normalize_path(input_path: str) -> Path:
    """æ­£è¦åŒ–ä¸¦é©—è­‰è¼¸å…¥è·¯å¾‘"""
    input_path = input_path.strip().strip('"').strip("'")
    path = Path(input_path).expanduser().resolve()
    return path


def extract_folder_name(path: Path) -> str:
    """æå–è³‡æ–™å¤¾åç¨±ä½œç‚ºè¼¸å‡ºæª”å"""
    return path.name


def find_matching_pairs(folder: Path) -> list:
    """
    æƒæè³‡æ–™å¤¾ï¼Œæ‰¾å‡º PNG/JPG èˆ‡ MP3 çš„é…å°
    å›å‚³: [(åºè™Ÿ, åœ–ç‰‡è·¯å¾‘, mp3è·¯å¾‘), ...]
    """
    image_files = {}
    mp3_files = {}
    
    for file in folder.iterdir():
        if file.name in IGNORE_FILES:
            continue
        
        stem = file.stem
        suffix = file.suffix.lower()
        
        if suffix in (".png", ".jpg", ".jpeg"):
            image_files[stem] = file
        elif suffix == ".mp3":
            mp3_files[stem] = file
    
    common_keys = set(image_files.keys()) & set(mp3_files.keys())
    
    if not common_keys:
        return []
    
    pairs = []
    # æ•¸å­—æ’åºï¼š1, 2, 3, ..., 9, 10, 11 è€Œéå­—æ¯æ’åº 1, 10, 11, 2, 3
    def numeric_sort_key(x):
        try:
            return (0, int(x))  # ç´”æ•¸å­—æ’åœ¨å‰é¢
        except ValueError:
            return (1, x)  # éæ•¸å­—æŒ‰å­—æ¯æ’åº
    
    for key in sorted(common_keys, key=numeric_sort_key):
        pairs.append((key, image_files[key], mp3_files[key]))
    
    unmatched_images = set(image_files.keys()) - common_keys
    unmatched_mp3 = set(mp3_files.keys()) - common_keys
    
    if unmatched_images:
        print(f"âš ï¸  è­¦å‘Šï¼šä»¥ä¸‹åœ–ç‰‡æª”æ¡ˆæ²’æœ‰å°æ‡‰çš„ MP3ï¼š{sorted(unmatched_images)}")
    if unmatched_mp3:
        print(f"âš ï¸  è­¦å‘Šï¼šä»¥ä¸‹ MP3 æª”æ¡ˆæ²’æœ‰å°æ‡‰çš„åœ–ç‰‡ï¼š{sorted(unmatched_mp3)}")
    
    return pairs


def concat_audio_with_ffmpeg(pairs: list, output_path: Path) -> Path:
    """ä½¿ç”¨ FFmpeg ç›´æ¥æ‹¼æ¥ MP3 æª”æ¡ˆ"""
    print("\nğŸ”Š ä½¿ç”¨ FFmpeg æ‹¼æ¥éŸ³æª”...")
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        for seq, _, mp3_path in pairs:
            f.write(f"file '{mp3_path}'\n")
        filelist_path = f.name
    
    try:
        result = subprocess.run([
            'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
            '-i', filelist_path,
            '-c', 'copy',
            str(output_path)
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âš ï¸  FFmpeg è­¦å‘Šï¼š{result.stderr[-500:] if result.stderr else 'unknown'}")
        
        print(f"   âœ… éŸ³æª”æ‹¼æ¥å®Œæˆï¼š{output_path}")
        return output_path
        
    finally:
        os.unlink(filelist_path)


def resize_image_cover(image_path: Path, target_width: int, target_height: int) -> np.ndarray:
    """å°‡åœ–ç‰‡ä»¥ cover æ¨¡å¼ç¸®æ”¾"""
    img = Image.open(str(image_path))
    orig_width, orig_height = img.size
    
    scale_w = target_width / orig_width
    scale_h = target_height / orig_height
    scale = max(scale_w, scale_h)
    
    new_width = int(orig_width * scale)
    new_height = int(orig_height * scale)
    img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
    
    left = (new_width - target_width) // 2
    top = (new_height - target_height) // 2
    right = left + target_width
    bottom = top + target_height
    
    img = img.crop((left, top, right, bottom))
    
    if img.mode != 'RGB':
        img = img.convert('RGB')
    
    return np.array(img)


def create_circle_mask(size: int) -> np.ndarray:
    """å»ºç«‹åœ“å½¢é®ç½©"""
    mask = Image.new('L', (size, size), 0)
    draw = ImageDraw.Draw(mask)
    draw.ellipse((0, 0, size - 1, size - 1), fill=255)
    return np.array(mask) / 255.0


# ============================================================
# å­—å¹•è™•ç†å‡½æ•¸
# ============================================================
def parse_srt(srt_path: Path) -> list:
    """
    è§£æ SRT å­—å¹•æª”æ¡ˆ
    å›å‚³: [{"start": float, "end": float, "text": str}, ...]
    """
    with open(srt_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    pattern = r"(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.+?)(?=\n\n|\n*$)"
    matches = re.findall(pattern, content, re.DOTALL)
    
    subtitles = []
    for match in matches:
        idx, start_str, end_str, text = match
        
        def parse_timestamp(ts: str) -> float:
            h, m, rest = ts.split(":")
            s, ms = rest.split(",")
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        
        subtitles.append({
            "start": parse_timestamp(start_str),
            "end": parse_timestamp(end_str),
            "text": text.strip().replace("\n", " ")
        })
    
    return subtitles


def create_subtitle_clips(subtitles: list, video_duration: float) -> list:
    """æ ¹æ“šå­—å¹•åˆ—è¡¨å»ºç«‹ TextClip ç‰©ä»¶"""
    clips = []
    
    for sub in subtitles:
        if sub["start"] >= video_duration:
            continue
        
        end_time = min(sub["end"], video_duration)
        duration = end_time - sub["start"]
        
        if duration <= 0:
            continue
        
        try:
            txt_clip = TextClip(
                text=sub["text"] + "\n ",  # HACK: é˜²æ­¢æé‚Šè¢«åˆ‡æ–·
                font_size=SubtitleConfig.FONT_SIZE,
                color=SubtitleConfig.COLOR,
                stroke_color=SubtitleConfig.STROKE_COLOR,
                stroke_width=SubtitleConfig.STROKE_WIDTH,
                font=SubtitleConfig.FONT_PATH,
                method="caption",
                size=(VideoConfig.WIDTH - 100, None),
                text_align="center"
            )
            
            # ä¸­å¿ƒå°é½Š
            visible_height = txt_clip.h / 2
            position_y = SubtitleConfig.CENTER_Y - (visible_height / 2)
            txt_clip = txt_clip.with_position(("center", position_y))
            
            txt_clip = txt_clip.with_start(sub["start"]).with_duration(duration)
            clips.append(txt_clip)
            
        except Exception as e:
            print(f"âš ï¸  å­—å¹•å»ºç«‹å¤±æ•—ï¼š{sub['text'][:20]}... ({e})")
    
    return clips


# ============================================================
# ä¸»è¦è™•ç†é‚è¼¯
# ============================================================
def build_base_track(pairs: list, merged_audio_path: Path):
    """å»ºç«‹ 16:9 åŸºç¤è»Œ"""
    clips = []
    
    for idx, (seq, image_path, mp3_path) in enumerate(pairs, 1):
        suffix = image_path.suffix.lower()
        print(f"   ğŸ“„ è™•ç†ä¸­ [{idx}/{len(pairs)}]: {seq}{suffix} + {seq}.mp3")
        
        audio = AudioFileClip(str(mp3_path))
        duration = audio.duration
        audio.close()
        
        img_array = resize_image_cover(image_path, VideoConfig.WIDTH, VideoConfig.HEIGHT)
        image = ImageClip(img_array).with_duration(duration)
        
        clips.append(image)
    
    print("\n   ğŸ”— æ­£åœ¨ä¸²æ¥æ‰€æœ‰ç‰‡æ®µ...")
    base_track = concatenate_videoclips(clips, method="compose")
    
    print("   ğŸ”Š ç¶å®šåˆä½µéŸ³æª”...")
    merged_audio = AudioFileClip(str(merged_audio_path))
    base_track = base_track.with_audio(merged_audio)
    
    return base_track


def create_avatar_overlay(avatar_path: Path, base_duration: float):
    """å»ºç«‹äººé ­ç–ŠåŠ å±¤"""
    print(f"\nğŸ‘¤ è™•ç† Avatar å½±ç‰‡...")
    
    avatar = VideoFileClip(str(avatar_path)).with_audio(None)
    orig_w, orig_h = avatar.w, avatar.h
    print(f"   ğŸ“ åŸå§‹å°ºå¯¸ï¼š{orig_w}x{orig_h}")
    
    crop_x = AvatarConfig.CROP_X
    crop_y = AvatarConfig.CROP_Y
    crop_size = min(AvatarConfig.CROP_SIZE, orig_w - crop_x, orig_h - crop_y)
    
    print(f"   âœ‚ï¸  è£åˆ‡å€åŸŸï¼š({crop_x}, {crop_y}) å¤§å° {crop_size}x{crop_size}")
    avatar = avatar.cropped(x1=crop_x, y1=crop_y, x2=crop_x + crop_size, y2=crop_y + crop_size)
    
    target_avatar_size = int(VideoConfig.WIDTH * AvatarConfig.SCALE_RATIO)
    print(f"   ğŸ“ ç¸®æ”¾è‡³ï¼š{target_avatar_size}x{target_avatar_size}")
    avatar = avatar.resized((target_avatar_size, target_avatar_size))
    
    circle_mask = create_circle_mask(target_avatar_size)
    mask_clip = ImageClip(circle_mask, is_mask=True).with_duration(avatar.duration)
    mask_clip = mask_clip.with_fps(avatar.fps)
    avatar = avatar.with_mask(mask_clip)
    
    pos_x = VideoConfig.WIDTH - target_avatar_size - AvatarConfig.MARGIN_X
    pos_y = VideoConfig.HEIGHT - target_avatar_size - AvatarConfig.MARGIN_Y
    print(f"   ğŸ“ å®šä½ï¼š({pos_x}, {pos_y})")
    
    avatar = avatar.with_position((pos_x, pos_y))
    
    if avatar.duration > base_duration:
        print(f"   âœ‚ï¸  è£åˆ‡ Avatarï¼š{avatar.duration:.2f}s â†’ {base_duration:.2f}s")
        avatar = avatar.subclipped(0, base_duration)
    elif avatar.duration < base_duration:
        print(f"   â„¹ï¸  Avatar è¼ƒçŸ­ï¼ˆ{avatar.duration:.2f}sï¼‰ï¼Œå°‡åœ¨ {avatar.duration:.2f}s å¾Œæ¶ˆå¤±")
    
    return avatar


def render_final_video(base_track, avatar_overlay, subtitle_clips: list, output_path: Path):
    """æœ€çµ‚åˆæˆèˆ‡æ¸²æŸ“"""
    print(f"\nğŸ¬ é–‹å§‹æœ€çµ‚æ¸²æŸ“...")
    print(f"   ğŸ“Š å½±ç‰‡é•·åº¦ï¼š{base_track.duration:.2f} ç§’")
    print(f"   ğŸ“ å­—å¹•æ•¸é‡ï¼š{len(subtitle_clips)} æ¢")
    print(f"   ğŸ“ è¼¸å‡ºä½ç½®ï¼š{output_path}")
    
    all_clips = [base_track, avatar_overlay] + subtitle_clips
    
    final = CompositeVideoClip(
        all_clips,
        size=(VideoConfig.WIDTH, VideoConfig.HEIGHT)
    )
    
    final.write_videofile(
        str(output_path),
        fps=VideoConfig.FPS,
        codec=VideoConfig.CODEC,
        audio_codec=VideoConfig.AUDIO_CODEC,
        threads=4,
        preset=VideoConfig.PRESET
    )
    
    final.close()
    base_track.close()
    avatar_overlay.close()
    for clip in subtitle_clips:
        clip.close()
    
    print(f"\nâœ… å®Œæˆï¼å½±ç‰‡å·²å„²å­˜è‡³ï¼š{output_path}")


# ============================================================
# å¼•æ“å…¥å£
# ============================================================
def run(folder_path: Path, output_path: Path):
    """
    MoviePy å¼•æ“ä¸»å…¥å£
    
    Args:
        folder_path: ç´ æè³‡æ–™å¤¾è·¯å¾‘
        output_path: è¼¸å‡ºå½±ç‰‡è·¯å¾‘
    """
    print("\nğŸ¬ ä½¿ç”¨ MoviePy å¼•æ“")
    print("=" * 50)
    
    # æª¢æŸ¥ avatar å½±ç‰‡
    avatar_path = folder_path / FileNames.AVATAR_FILE
    if not avatar_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° Avatar å½±ç‰‡ï¼š{avatar_path}")
    
    # æª¢æŸ¥å­—å¹•æª”æ¡ˆ
    subtitle_path = folder_path / FileNames.SUBTITLE_FILE
    subtitles = []
    if subtitle_path.exists():
        print(f"ğŸ“ ç™¼ç¾å­—å¹•æª”æ¡ˆï¼š{subtitle_path}")
        subtitles = parse_srt(subtitle_path)
        print(f"   âœ… è¼‰å…¥ {len(subtitles)} æ¢å­—å¹•")
    else:
        print(f"â„¹ï¸  æœªç™¼ç¾å­—å¹•æª”æ¡ˆï¼Œå°‡ä¸ç‡’éŒ„å­—å¹•")
    
    # æƒæç´ æ
    print("\nğŸ” æƒæç´ æ...")
    pairs = find_matching_pairs(folder_path)
    
    if not pairs:
        raise ValueError("æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡/MP3 é…å°")
    
    print(f"   âœ… æ‰¾åˆ° {len(pairs)} çµ„é…å°\n")
    
    # æ‹¼æ¥éŸ³æª”
    merged_audio_path = folder_path / FileNames.MERGED_AUDIO
    concat_audio_with_ffmpeg(pairs, merged_audio_path)
    
    # å»ºç«‹åŸºç¤è»Œ
    print("\nğŸï¸  å»ºç«‹åŸºç¤è»Œ...")
    base_track = build_base_track(pairs, merged_audio_path)
    
    # å»ºç«‹ avatar ç–ŠåŠ å±¤
    avatar_overlay = create_avatar_overlay(avatar_path, base_track.duration)
    
    # å»ºç«‹å­—å¹• clips
    subtitle_clips = []
    if subtitles:
        print("\nğŸ“ å»ºç«‹å­—å¹•åœ–å±¤...")
        subtitle_clips = create_subtitle_clips(subtitles, base_track.duration)
        print(f"   âœ… æˆåŠŸå»ºç«‹ {len(subtitle_clips)} å€‹å­—å¹•ç‰‡æ®µ")
    
    # æœ€çµ‚æ¸²æŸ“
    render_final_video(base_track, avatar_overlay, subtitle_clips, output_path)
    
    # æ¸…ç†æš«å­˜
    if merged_audio_path.exists():
        merged_audio_path.unlink()
        print(f"ğŸ§¹ å·²æ¸…ç†æš«å­˜éŸ³æª”")
