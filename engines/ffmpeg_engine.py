#!/usr/bin/env python3
"""
FFmpeg å¼•æ“ - ä½¿ç”¨ç´” FFmpeg å‘½ä»¤é€²è¡Œå½±ç‰‡åˆæˆ
é«˜æ•ˆèƒ½ç‰ˆæœ¬ï¼Œé©åˆé•·å½±ç‰‡è™•ç†
"""

import os
import subprocess
import tempfile
import re
import concurrent.futures
import threading
import time
from pathlib import Path
import wave  # æ¨™æº–åº«ï¼Œç”¨æ–¼è®€å– WAV
import numpy as np
from typing import List, Tuple, Dict  # æ›´æ–° Type Hints

from config import (
    VideoConfig,
    ProcessingConfig,
    SubtitleConfig,
    AvatarConfig,
    FileNames,
    IGNORE_FILES
)


# ============================================================
# å·¥å…·å‡½æ•¸
# ============================================================
def find_matching_pairs(folder: Path) -> List[Tuple[str, Path, Path]]:
    """æƒæè³‡æ–™å¤¾ï¼Œæ‰¾å‡º PNG/JPG èˆ‡ MP3 çš„é…å°"""
    image_files = {}
    mp3_files = {}
    
    for file in folder.iterdir():
        if file.name in IGNORE_FILES:
            continue
        
        stem = file.stem
        suffix = file.suffix.lower()
        
        if suffix in (".png", ".jpg", ".jpeg"):
            image_files[stem] = file
        elif suffix == ".mp3":
            mp3_files[stem] = file
    
    common_keys = set(image_files.keys()) & set(mp3_files.keys())
    
    if not common_keys:
        return []
    
    pairs = []
    # æ•¸å­—æ’åºï¼š1, 2, 3, ..., 9, 10, 11 è€Œéå­—æ¯æ’åº 1, 10, 11, 2, 3
    def numeric_sort_key(x):
        try:
            return (0, int(x))  # ç´”æ•¸å­—æ’åœ¨å‰é¢
        except ValueError:
            return (1, x)  # éæ•¸å­—æŒ‰å­—æ¯æ’åº
    
    for key in sorted(common_keys, key=numeric_sort_key):
        pairs.append((key, image_files[key], mp3_files[key]))
    
    unmatched_images = set(image_files.keys()) - common_keys
    unmatched_mp3 = set(mp3_files.keys()) - common_keys
    
    if unmatched_images:
        print(f"âš ï¸  è­¦å‘Šï¼šä»¥ä¸‹åœ–ç‰‡æª”æ¡ˆæ²’æœ‰å°æ‡‰çš„ MP3ï¼š{sorted(unmatched_images)}")
    if unmatched_mp3:
        print(f"âš ï¸  è­¦å‘Šï¼šä»¥ä¸‹ MP3 æª”æ¡ˆæ²’æœ‰å°æ‡‰çš„åœ–ç‰‡ï¼š{sorted(unmatched_mp3)}")
    
    return pairs


def get_audio_duration(audio_path: Path) -> float:
    """ä½¿ç”¨ ffprobe å–å¾—éŸ³è¨Šé•·åº¦"""
    result = subprocess.run([
        'ffprobe', '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        str(audio_path)
    ], capture_output=True, text=True)
    return float(result.stdout.strip())


def get_video_duration(video_path: Path) -> float:
    """ä½¿ç”¨ ffprobe å–å¾—å½±ç‰‡é•·åº¦"""
    result = subprocess.run([
        'ffprobe', '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        str(video_path)
    ], capture_output=True, text=True)
    return float(result.stdout.strip())


def read_audio_data(audio_path: Path, target_sr: int = 8000) -> np.ndarray:
    """
    ä½¿ç”¨ ffmpeg å°‡éŸ³è¨Šè½‰æ›ç‚º raw wav æ•¸æ“šä¸¦è®€å–ç‚º numpy array
    ä½¿ç”¨è¼ƒä½çš„æ¡æ¨£ç‡ (8000Hz) ä»¥åŠ å¿«è¨ˆç®—é€Ÿåº¦ï¼Œå°æ–¼å°é½Šä¾†èªªå·²ç¶“è¶³å¤ ç²¾ç¢º
    """
    # ä½¿ç”¨ temp file å„²å­˜è½‰æ›å¾Œçš„ wav
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tf:
        temp_wav = str(tf.name)
    
    try:
        # è½‰æ›ç‚ºå–®è²é“ã€16bit PCMã€æŒ‡å®šæ¡æ¨£ç‡
        cmd = [
            'ffmpeg', '-y', '-v', 'error',
            '-i', str(audio_path),
            '-ac', '1',  # å–®è²é“
            '-ar', str(target_sr),  # æ¡æ¨£ç‡
            '-c:a', 'pcm_s16le',  # 16-bit PCM
            temp_wav
        ]
        subprocess.run(cmd, check=True)
        
        # è®€å– wav
        with wave.open(temp_wav, 'rb') as wf:
            n_frames = wf.getnframes()
            frames = wf.readframes(n_frames)
            # è½‰æ›ç‚º numpy array (int16)
            audio_data = np.frombuffer(frames, dtype=np.int16)
            # æ­£è¦åŒ–åˆ° -1.0 ~ 1.0 (float32) ä»¥ä¾¿é€²è¡Œ FFT
            return audio_data.astype(np.float32) / 32768.0
            
    finally:
        if os.path.exists(temp_wav):
            os.unlink(temp_wav)


def find_audio_offset(main_audio: np.ndarray, segment_audio: np.ndarray, sr: int = 8000, start_hint: float = 0.0) -> float:
    """
    ä½¿ç”¨ FFT Cross-Correlation æ‰¾å‡º segment åœ¨ main ä¸­çš„é–‹å§‹æ™‚é–“
    """
    if len(segment_audio) > len(main_audio):
        return 0.0
        
    # å„ªåŒ–ï¼šåªåœ¨ hint é™„è¿‘æœå°‹ï¼Ÿ
    # ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘å…ˆå°å…¨åŸŸæœå°‹ï¼Œä½†ç‚ºäº†é¿å…è¨ˆç®—é‡éå¤§æˆ–èª¤åˆ¤ï¼Œ
    # å¦‚æœ main audio çœŸçš„å¾ˆé•· (ä¾‹å¦‚ > 10åˆ†é˜)ï¼Œå¯ä»¥è€ƒæ…®åˆ‡ç‰‡ã€‚
    # ç›®å‰ 10 åˆ†é˜ 8000Hz = 4.8M é»ï¼ŒFFT æ‡‰è©²é‚„åœ¨å¹¾ç§’å…§å¯å®Œæˆã€‚
    
    n = len(main_audio)
    
    # å¡«å…… segment åˆ°ç›¸åŒé•·åº¦
    segment_padded = np.zeros(n, dtype=np.float32)
    segment_padded[:len(segment_audio)] = segment_audio
    
    # ä½¿ç”¨ FFT è¨ˆç®— Cross Correlation
    # Correlation = IFFT( FFT(Main) * Conj(FFT(Segment)) )
    # æ³¨æ„ï¼šé€™è¨ˆç®—çš„æ˜¯ Circular Correlation
    
    f_main = np.fft.rfft(main_audio)
    f_seg = np.fft.rfft(segment_padded)
    
    # è¨ˆç®— correlation (æ³¨æ„ conjugat)
    # æˆ‘å€‘å¸Œæœ›æ‰¾åˆ° segment åœ¨ main ä¸­çš„ä½ç½®ï¼Œé€™ç›¸ç•¶æ–¼æ»‘å‹• segment
    # å¯¦éš›ä¸Šï¼Œæ¨™æº–çš„ correlation æ˜¯ sum(f * g)ï¼Œé€™è£¡ç”¨é »åŸŸä¹˜æ³•
    corr = np.fft.irfft(f_main * np.conj(f_seg))
    
    # æ‰¾å‡ºæœ€å¤§å€¼ä½ç½®
    # ç‚ºäº†é¿å…èª¤åˆ¤ï¼Œæˆ‘å€‘å¯ä»¥é™åˆ¶æœå°‹ç¯„åœåœ¨ hint é™„è¿‘ (ä¾‹å¦‚ +/- 10ç§’)
    hint_idx = int(start_hint * sr)
    window = int(10.0 * sr)  # +/- 10ç§’
    
    search_start = max(0, hint_idx - window // 2)
    search_end = min(n, hint_idx + window * 2) # å‘å¾Œå¤šæ‰¾ä¸€é»
    
    # åªåœ¨è¦–çª—å…§æ‰¾æœ€å¤§å€¼
    if search_start < search_end:
        peak_idx = search_start + np.argmax(corr[search_start:search_end])
    else:
        peak_idx = np.argmax(corr)
        
    return peak_idx / sr


# ============================================================
# SRT â†’ ASS è½‰æ›
# ============================================================
def parse_srt(srt_path: Path) -> list:
    """è§£æ SRT å­—å¹•æª”æ¡ˆ"""
    with open(srt_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    pattern = r"(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.+?)(?=\n\n|\n*$)"
    matches = re.findall(pattern, content, re.DOTALL)
    
    subtitles = []
    for match in matches:
        idx, start_str, end_str, text = match
        subtitles.append({
            "start": start_str.replace(",", "."),  # ASS ç”¨é»è™Ÿ
            "end": end_str.replace(",", "."),
            "text": text.strip().replace("\n", "\\N")  # ASS æ›è¡Œç¬¦
        })
    
    return subtitles


def generate_ass_file(srt_path: Path, ass_path: Path):
    """
    å°‡ SRT è½‰æ›ç‚º ASS æ ¼å¼
    ASS å¯ä»¥ç²¾ç¢ºæ§åˆ¶å­—é«”ã€é¡è‰²ã€ä½ç½®
    """
    subtitles = parse_srt(srt_path)
    
    # è¨ˆç®— MarginVï¼ˆå‚ç›´é‚Šè·ï¼‰
    # ASS çš„ alignment=2 æ˜¯åº•éƒ¨ç½®ä¸­
    # MarginV æ˜¯å¾åº•éƒ¨ç®—èµ·çš„è·é›¢
    margin_v = VideoConfig.HEIGHT - SubtitleConfig.CENTER_Y - (SubtitleConfig.FONT_SIZE // 2)
    
    # ASS é¡è‰²æ ¼å¼ï¼š&HBBGGRRï¼ˆBGR é †åºï¼Œä¸æ˜¯ RGBï¼‰
    def color_to_ass(color_name: str) -> str:
        colors = {
            "yellow": "&H00FFFF",
            "white": "&HFFFFFF",
            "black": "&H000000",
            "red": "&H0000FF",
        }
        return colors.get(color_name.lower(), "&HFFFFFF")
    
    primary_color = color_to_ass(SubtitleConfig.COLOR)
    outline_color = color_to_ass(SubtitleConfig.STROKE_COLOR)
    
    # ASS æª”æ¡ˆé ­
    ass_content = f"""[Script Info]
Title: Auto Generated Subtitles
ScriptType: v4.00+
PlayResX: {VideoConfig.WIDTH}
PlayResY: {VideoConfig.HEIGHT}
WrapStyle: 0

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,PingFang TC,{SubtitleConfig.FONT_SIZE},{primary_color},&H000000FF,{outline_color},&H00000000,-1,0,0,0,100,100,0,0,1,{SubtitleConfig.STROKE_WIDTH},0,2,10,10,{margin_v},1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
    
    # æ·»åŠ å­—å¹•äº‹ä»¶
    for sub in subtitles:
        # æ™‚é–“æ ¼å¼è½‰æ›ï¼š00:00:01.500 â†’ 0:00:01.50
        def convert_time(t: str) -> str:
            parts = t.split(":")
            h = int(parts[0])
            m = parts[1]
            s = parts[2][:5]  # åªå–åˆ°å°æ•¸é»å¾Œå…©ä½
            return f"{h}:{m}:{s}"
        
        start = convert_time(sub["start"])
        end = convert_time(sub["end"])
        text = sub["text"]
        
        ass_content += f"Dialogue: 0,{start},{end},Default,,0,0,0,,{text}\n"
    
    with open(ass_path, "w", encoding="utf-8") as f:
        f.write(ass_content)
    
    print(f"   âœ… ASS å­—å¹•ç”Ÿæˆå®Œæˆï¼š{ass_path}")
    return ass_path


# ============================================================
# FFmpeg å½±ç‰‡è™•ç†
# ============================================================
def create_segment_videos(pairs: list, temp_dir: Path, durations: Dict[str, float]) -> List[Path]:
    """
    ç‚ºæ¯å€‹åœ–ç‰‡+éŸ³è¨Šé…å°å‰µå»ºå½±ç‰‡ç‰‡æ®µ
    [å¹³è¡Œè™•ç†ç‰ˆ] ä½¿ç”¨ ThreadPoolExecutor å¹³è¡Œç”Ÿæˆï¼Œå¤§å¹…åŠ é€Ÿ
    """
    segments = [None] * len(pairs)
    total_segments = len(pairs)
    completed_count = 0
    print_lock = threading.Lock()
    
    start_time_all = time.time()
    
    def process_single_segment(item):
        nonlocal completed_count
        idx, (seq, image_path, mp3_path) = item
        
        target_duration = durations.get(seq, 0.0)
        
        # å®‰å…¨æª¢æŸ¥
        original_duration = get_audio_duration(mp3_path)
        if target_duration < original_duration:
            with print_lock:
                 print(f"      âš ï¸  è­¦å‘Šï¼š[{seq}] ç›®æ¨™é•·åº¦ ({target_duration:.2f}s) å°æ–¼åŸå§‹éŸ³è¨Š ({original_duration:.2f}s)ï¼Œå°‡ä½¿ç”¨åŸå§‹é•·åº¦")
            target_duration = original_duration

        output_segment = temp_dir / f"segment_{seq}.mp4"
        
        cmd = [
            'ffmpeg', '-y',
            '-loop', '1',
            '-i', str(image_path),
            '-i', str(mp3_path),
            '-c:v', VideoConfig.CODEC,
            '-tune', 'stillimage',
            '-c:a', VideoConfig.AUDIO_CODEC,
            '-b:a', '192k',
            '-vf', f'scale={VideoConfig.WIDTH}:{VideoConfig.HEIGHT}:force_original_aspect_ratio=increase,crop={VideoConfig.WIDTH}:{VideoConfig.HEIGHT}',
            '-af', 'apad', # å¡«å……éœéŸ³ï¼Œç¢ºä¿éŸ³è¨Šé•·åº¦è·Ÿä¸Šå½±ç‰‡
            '-pix_fmt', 'yuv420p',
            # '-shortest', # ç§»é™¤ -shortestï¼Œå¦å‰‡æœƒæŠŠéœéŸ³è£æ‰å°è‡´æ¶æ‹
            '-t', str(target_duration),
            '-loglevel', 'error', # æ¸›å°‘æ—¥èªŒå¹²æ“¾
            str(output_segment)
        ]
        
        subprocess.run(cmd, capture_output=True, text=True)
        
        with print_lock:
            completed_count += 1
            # ç°¡æ˜“é€²åº¦æ¢
            percent = (completed_count / total_segments) * 100
            bar_length = 20
            filled_length = int(bar_length * completed_count // total_segments)
            bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
            
            print(f"   â–•{bar}â– {percent:5.1f}% | å®Œæˆç‰‡æ®µ: {seq} (æŒçºŒ: {target_duration:.2f}s)", end="\r")
            
        return idx, output_segment

    # æº–å‚™åƒæ•¸
    work_items = []
    for idx, (seq, image_path, mp3_path) in enumerate(pairs):
        work_items.append((idx, (seq, image_path, mp3_path)))
        
    # å¹³è¡ŒåŸ·è¡Œ (Max Workers ç”± config æ±ºå®š)
    max_workers = ProcessingConfig.MAX_WORKERS
    print(f"   ğŸš€ å•Ÿå‹•å¹³è¡Œè™•ç† (Workers: {max_workers})...")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(process_single_segment, work_items))
        
    print() # æ›è¡Œ
    
    # æŒ‰ç…§åŸå§‹é †åºé‡çµ„
    for idx, path in results:
        segments[idx] = path
        
    elapsed = time.time() - start_time_all
    print(f"   âœ… å…¨éƒ¨ç‰‡æ®µç”Ÿæˆå®Œæˆï¼Œè€—æ™‚: {elapsed:.2f}s")
    
    return segments


def concat_segments(segments: List[Path], output_path: Path):
    """ä½¿ç”¨ FFmpeg concat demuxer ä¸²æ¥å½±ç‰‡ç‰‡æ®µ"""
    print("\n   ğŸ”— æ­£åœ¨ä¸²æ¥æ‰€æœ‰ç‰‡æ®µ...")
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        for seg in segments:
            f.write(f"file '{seg}'\n")
        filelist_path = f.name
    
    try:
        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat', '-safe', '0',
            '-i', filelist_path,
            '-c', 'copy',
            str(output_path)
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"âš ï¸  FFmpeg ä¸²æ¥è­¦å‘Šï¼š{result.stderr[-300:] if result.stderr else 'unknown'}")
        
        print(f"   âœ… ç‰‡æ®µä¸²æ¥å®Œæˆ")
        
    finally:
        os.unlink(filelist_path)


def create_avatar_overlay_video(avatar_path: Path, duration: float, temp_dir: Path) -> Path:
    """
    è™•ç† Avatar å½±ç‰‡ï¼šè£åˆ‡ â†’ ç¸®æ”¾ â†’ åœ“å½¢é®ç½©
    ä½¿ç”¨ geq æ¿¾é¡å‰µå»ºåœ“å½¢é®ç½©
    """
    print(f"\nğŸ‘¤ è™•ç† Avatar å½±ç‰‡...")
    
    crop_x = AvatarConfig.CROP_X
    crop_y = AvatarConfig.CROP_Y
    crop_size = AvatarConfig.CROP_SIZE
    target_size = int(VideoConfig.WIDTH * AvatarConfig.SCALE_RATIO)
    
    pos_x = VideoConfig.WIDTH - target_size - AvatarConfig.MARGIN_X
    pos_y = VideoConfig.HEIGHT - target_size - AvatarConfig.MARGIN_Y
    
    print(f"   âœ‚ï¸  è£åˆ‡å€åŸŸï¼š({crop_x}, {crop_y}) å¤§å° {crop_size}x{crop_size}")
    print(f"   ğŸ“ ç¸®æ”¾è‡³ï¼š{target_size}x{target_size}")
    print(f"   ğŸ“ å®šä½ï¼š({pos_x}, {pos_y})")
    
    output_avatar = temp_dir / "avatar_processed.mov"
    
    avatar_duration = get_video_duration(avatar_path)
    actual_duration = min(avatar_duration, duration)
    
    if avatar_duration < duration:
        print(f"   â„¹ï¸  Avatar è¼ƒçŸ­ï¼ˆ{avatar_duration:.2f}sï¼‰ï¼Œå°‡åœ¨ {avatar_duration:.2f}s å¾Œæ¶ˆå¤±")
    
    # FFmpeg è¤‡é›œæ¿¾é¡ï¼šè£åˆ‡ â†’ ç¸®æ”¾ â†’ åœ“å½¢é®ç½©ï¼ˆä½¿ç”¨ geq æ¿¾é¡ï¼‰
    # geq æ¿¾é¡è¨ˆç®—æ¯å€‹åƒç´ åˆ°ä¸­å¿ƒçš„è·é›¢ï¼Œè¶…å‡ºåŠå¾‘å‰‡é€æ˜
    radius = target_size // 2
    center = target_size // 2
    
    # ä½¿ç”¨ format=rgba å’Œ geq ä¾†å‰µå»ºåœ“å½¢é®ç½©
    filter_complex = (
        f"crop={crop_size}:{crop_size}:{crop_x}:{crop_y},"
        f"scale={target_size}:{target_size},"
        f"format=rgba,"
        f"geq=lum='p(X,Y)':a='if(gt(sqrt(pow(X-{center},2)+pow(Y-{center},2)),{radius}),0,255)'"
    )
    
    cmd = [
        'ffmpeg', '-y',
        '-i', str(avatar_path),
        '-vf', filter_complex,
        '-c:v', 'qtrle',  # QuickTime Animation codec æ”¯æ´ RGBA
        '-t', str(actual_duration),
        '-an',  # ç„¡éŸ³è¨Š
        str(output_avatar)
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"âš ï¸  Avatar è™•ç†è­¦å‘Šï¼š{result.stderr[-300:] if result.stderr else 'unknown'}")
        # å¦‚æœ geq å¤±æ•—ï¼Œå˜—è©¦ä¸ä½¿ç”¨åœ“å½¢é®ç½©çš„å‚™ç”¨æ–¹æ¡ˆ
        print("   âš ï¸  å˜—è©¦å‚™ç”¨æ–¹æ¡ˆï¼ˆç„¡åœ“å½¢é®ç½©ï¼‰...")
        fallback_filter = (
            f"crop={crop_size}:{crop_size}:{crop_x}:{crop_y},"
            f"scale={target_size}:{target_size}"
        )
        fallback_cmd = [
            'ffmpeg', '-y',
            '-i', str(avatar_path),
            '-vf', fallback_filter,
            '-c:v', VideoConfig.CODEC,
            '-t', str(actual_duration),
            '-an',
            str(output_avatar)
        ]
        result = subprocess.run(fallback_cmd, capture_output=True, text=True)
        if result.returncode != 0:
            raise RuntimeError(f"Avatar è™•ç†å¤±æ•—ï¼š{result.stderr[-300:]}")
    
    print(f"   âœ… Avatar è™•ç†å®Œæˆ")
    return output_avatar


def composite_final_video(
    base_video: Path,
    avatar_video: Path,
    original_avatar_path: Path,  # æ–°å¢ï¼šåŸå§‹ Avatar æª”æ¡ˆï¼ˆéŸ³è¨Šä¾†æºï¼‰
    ass_path: Path,
    output_path: Path
):
    """
    æœ€çµ‚åˆæˆï¼šåŸºç¤è»Œ + Avatar ç–ŠåŠ  + å­—å¹•ç‡’éŒ„
    éŸ³è¨Šä¾†æºï¼šä½¿ç”¨åŸå§‹ Avatar å½±ç‰‡çš„éŸ³è»Œ (Single Source of Truth)
    """
    print(f"\nğŸ¬ é–‹å§‹æœ€çµ‚åˆæˆ...")
    
    target_size = int(VideoConfig.WIDTH * AvatarConfig.SCALE_RATIO)
    pos_x = VideoConfig.WIDTH - target_size - AvatarConfig.MARGIN_X
    pos_y = VideoConfig.HEIGHT - target_size - AvatarConfig.MARGIN_Y
    
    # æ§‹å»ºæ¿¾é¡
    if ass_path and ass_path.exists():
        # æœ‰å­—å¹•ï¼šç–ŠåŠ  Avatar + ç‡’éŒ„å­—å¹•
        # è·¨å¹³å°è·¯å¾‘è™•ç†ï¼šä½¿ç”¨ as_posix() çµ±ä¸€ç‚ºæ­£æ–œç·šï¼Œå†è½‰ç¾©å†’è™Ÿ
        ass_escaped = ass_path.as_posix().replace(":", "\\:")
        filter_complex = (
            f"[0:v][1:v]overlay={pos_x}:{pos_y}[composited];"  # ç§»é™¤ shortest=1ï¼Œè®“é•·åº¦è·Ÿéš¨æœ€é•·çš„æµï¼ˆé€šå¸¸æ˜¯éŸ³è¨Šï¼‰
            f"[composited]ass='{ass_escaped}'[out]"
        )
    else:
        # ç„¡å­—å¹•ï¼šåªç–ŠåŠ  Avatar
        filter_complex = f"[0:v][1:v]overlay={pos_x}:{pos_y}[out]"
    
    cmd = [
        'ffmpeg', '-y',
        '-i', str(base_video),          # Input 0: åŸºç¤è¦–è¦ºè»Œ (ç”±ç‰‡æ®µæ‹¼æ¥)
        '-i', str(avatar_video),        # Input 1: è™•ç†å¾Œçš„åœ“å½¢ Avatar (ç„¡è²)
        '-i', str(original_avatar_path),# Input 2: åŸå§‹ Avatar (å–å…¶éŸ³è¨Š)
        '-filter_complex', filter_complex,
        '-map', '[out]',                # å½±åƒä¾†è‡ªæ¿¾é¡è¼¸å‡º
        '-map', '2:a',                  # éŸ³è¨Šä¾†è‡ªåŸå§‹ Avatar
        '-c:v', VideoConfig.CODEC,
        '-preset', VideoConfig.PRESET,
        '-c:a', VideoConfig.AUDIO_CODEC,
        '-b:a', '192k',
        str(output_path)
    ]
    
    print(f"   ğŸ“ è¼¸å‡ºä½ç½®ï¼š{output_path}")
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"âš ï¸  æœ€çµ‚åˆæˆè­¦å‘Šï¼š{result.stderr[-500:] if result.stderr else 'unknown'}")
        raise RuntimeError(f"FFmpeg åˆæˆå¤±æ•—ï¼š{result.stderr[-500:]}")
    
    print(f"\nâœ… å®Œæˆï¼å½±ç‰‡å·²å„²å­˜è‡³ï¼š{output_path}")


# ============================================================
# å¼•æ“å…¥å£
# ============================================================
def run(folder_path: Path, output_path: Path):
    """
    FFmpeg å¼•æ“ä¸»å…¥å£
    
    Args:
        folder_path: ç´ æè³‡æ–™å¤¾è·¯å¾‘
        output_path: è¼¸å‡ºå½±ç‰‡è·¯å¾‘
    """
    print("\nğŸš€ ä½¿ç”¨ FFmpeg å¼•æ“ï¼ˆé«˜æ•ˆèƒ½æ¨¡å¼ï¼‰")
    print("=" * 50)
    
    # æª¢æŸ¥ avatar å½±ç‰‡
    avatar_path = folder_path / FileNames.AVATAR_FILE
    if not avatar_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° Avatar å½±ç‰‡ï¼š{avatar_path}")
    
    # æª¢æŸ¥å­—å¹•æª”æ¡ˆ
    subtitle_path = folder_path / FileNames.SUBTITLE_FILE
    ass_path = None
    if subtitle_path.exists():
        print(f"ğŸ“ ç™¼ç¾å­—å¹•æª”æ¡ˆï¼š{subtitle_path}")
    else:
        print(f"â„¹ï¸  æœªç™¼ç¾å­—å¹•æª”æ¡ˆï¼Œå°‡ä¸ç‡’éŒ„å­—å¹•")
    
    # æƒæç´ æ
    print("\nğŸ” æƒæç´ æ...")
    pairs = find_matching_pairs(folder_path)
    
    if not pairs:
        raise ValueError("æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡/MP3 é…å°")
    
    # Audio Fingerprinting Sync (éŸ³è¨ŠæŒ‡ç´‹å°é½Š)
    print("\nğŸ§ æ­£åœ¨é€²è¡Œ Audio Fingerprinting å°é½Š...")
    print("   è¼‰å…¥ Avatar éŸ³è»Œæ•¸æ“š (8000Hz)...")
    main_audio = read_audio_data(avatar_path, target_sr=8000)
    avatar_duration = len(main_audio) / 8000.0
    print(f"   ğŸ“Š Avatar éŸ³è»Œé•·åº¦: {avatar_duration:.2f}s")
    
    exact_durations = {}
    current_hint = 0.0
    
    start_times = {} # è¨˜éŒ„æ¯æ®µçš„é–‹å§‹æ™‚é–“ï¼Œç”¨æ–¼è¨ˆç®— duration
    
    # 1. æ‰¾å‡ºæ‰€æœ‰ç‰‡æ®µçš„é–‹å§‹æ™‚é–“
    for idx, (seq, _, mp3_path) in enumerate(pairs):
        print(f"   ğŸ” å°é½Šä¸­ [{idx+1}/{len(pairs)}]: {seq}.mp3...", end="\r")
        seg_audio = read_audio_data(mp3_path, target_sr=8000)
        
        # ä½¿ç”¨ FFT æ‰¾å‡ºç²¾ç¢ºä½ç½®
        start_time = find_audio_offset(main_audio, seg_audio, sr=8000, start_hint=current_hint)
        start_times[seq] = start_time
        
        # æ›´æ–° hint (ä¸‹ä¸€æ®µæ‡‰è©²åœ¨é€™ä¸€æ®µçµæŸå¾Œ)
        seg_duration = len(seg_audio) / 8000.0
        current_hint = start_time + seg_duration
        
    print("\n   âœ… å°é½Šå®Œæˆï¼Œè¨ˆç®—æ¯å¼µåœ–ç‰‡ç²¾ç¢ºæŒçºŒæ™‚é–“...")
    
    # 2. è¨ˆç®— duration = Next_Start - Current_Start
    # ã€ä¿®æ­£æ¶æ‹å•é¡Œã€‘ä½¿ç”¨ã€Œå¹€ç´šç²¾ç¢ºè¨ˆç®— (Frame-Perfect Calculation)ã€
    # é¿å…æµ®é»æ•¸ç§’æ•¸åœ¨è½‰ç‚ºå¹€æ•¸æ™‚ç”¢ç”Ÿé‡åŒ–èª¤å·®ç´¯ç© (Quantization Drift)
    
    sorted_pairs = pairs # pairs å·²ç¶“æŒ‰ç…§ seq æ’åºé
    fps = VideoConfig.FPS
    
    for i in range(len(sorted_pairs)):
        current_seq = sorted_pairs[i][0]
        current_start = start_times[current_seq]
        
        # å°‡ã€Œç§’æ•¸ã€è½‰æ›ç‚ºçµ•å°çš„ã€Œå¹€æ•¸ä½ç½®ã€ (å››æ¨äº”å…¥)
        # F_start[n] = Round( T_start[n] * FPS )
        current_frame_start = int(round(current_start * fps))
        
        if i < len(sorted_pairs) - 1:
            next_seq = sorted_pairs[i+1][0]
            next_start = start_times[next_seq]
            next_frame_start = int(round(next_start * fps))
            
            # Duration_Frames = Next_Frame_Start - Current_Frame_Start
            # é€™ä¿è­‰äº†æ‰€æœ‰ç‰‡æ®µåŠ èµ·ä¾†çš„ç¸½å¹€æ•¸ï¼Œåš´æ ¼ç­‰æ–¼ç¸½æ™‚é–“å°æ‡‰çš„å¹€æ•¸ï¼Œèª¤å·®ç‚º 0
            duration_frames = next_frame_start - current_frame_start
            
            # è½‰å›ç§’æ•¸çµ¦ FFmpeg ä½¿ç”¨ (FFmpeg æœƒè¦–ç‚ºç²¾ç¢ºçš„å¹€æ•¸æ•´æ•¸å€)
            duration = duration_frames / fps
            
            # å®‰å…¨æª¢æŸ¥
            if duration <= 0.1:
                print(f"   âš ï¸  è­¦å‘Šï¼šç‰‡æ®µ {current_seq} è¨ˆç®—å‡ºçš„æŒçºŒæ™‚é–“ç•°å¸¸ ({duration:.2f}s / {duration_frames} frames)ï¼Œä½¿ç”¨é è¨­å€¼")
                duration = get_audio_duration(sorted_pairs[i][2])
                
        else:
            # æœ€å¾Œä¸€æ®µï¼šæŒçºŒåˆ° Avatar çµæŸ
            # åŒæ¨£ä½¿ç”¨å¹€æ•¸è¨ˆç®—
            avatar_frame_len = int(round(avatar_duration * fps))
            duration_frames = avatar_frame_len - current_frame_start
            
            duration = duration_frames / fps
            
            if duration <= 0:
                 duration = get_audio_duration(sorted_pairs[i][2])
        
        exact_durations[current_seq] = duration
        # print(f"      - {current_seq}: {duration:.2f}s (Start: {current_start:.2f}s)")

    # Create temporary directory for processing
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # Step 1: å‰µå»ºå½±ç‰‡ç‰‡æ®µ
        print("\nğŸï¸  å»ºç«‹å½±ç‰‡ç‰‡æ®µ (ä½¿ç”¨ç²¾ç¢ºå°é½Šæ™‚é–“)...")
        segments = create_segment_videos(pairs, temp_path, exact_durations)
        
        # Step 2: ä¸²æ¥ç‰‡æ®µ
        base_video = temp_path / "base_track.mp4"
        concat_segments(segments, base_video)
        
        base_duration = get_video_duration(base_video)
        print(f"   ğŸ“Š åŸºç¤è»Œé•·åº¦ï¼š{base_duration:.2f} ç§’")
        
        # Step 3: è™•ç† Avatar
        avatar_processed = create_avatar_overlay_video(avatar_path, base_duration, temp_path)
        
        # Step 4: ç”Ÿæˆ ASS å­—å¹•
        if subtitle_path.exists():
            print("\nğŸ“ è½‰æ›å­—å¹•æ ¼å¼...")
            ass_path = temp_path / FileNames.ASS_SUBTITLE
            generate_ass_file(subtitle_path, ass_path)
        
        # Step 5: æœ€çµ‚åˆæˆ
        composite_final_video(base_video, avatar_processed, avatar_path, ass_path, output_path)
