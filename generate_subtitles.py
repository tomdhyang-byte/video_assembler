#!/usr/bin/env python3
"""
AI è‡ªå‹•å­—å¹•ç”Ÿæˆå™¨ V7 (Force Alignment ç‰ˆ)
Whisper å­—ç´šæ™‚é–“æˆ³ -> Python å¼·åˆ¶å°é½Š (ä¿®æ­£éŒ¯å­—èˆ‡æ™‚é–“) -> GPT æ®µè½åˆ‡åˆ† -> Python å­—å¹•å°é½Š

ä¸»è¦åŠŸèƒ½ï¼š
1. ä½¿ç”¨ faster-whisper ç”¢ç”Ÿå­—ç´šæ™‚é–“æˆ³
2. ä½¿ç”¨ difflib å°‡ Whisper è¾¨è­˜çµæœèˆ‡æ­£ç¢ºé€å­—ç¨¿å¼·åˆ¶å°é½Š (Force Alignment)
3. ä½¿ç”¨ GPT-4o-mini å°‡æ­£ç¢ºé€å­—ç¨¿ä¾èªæ„å’Œå­—æ•¸é™åˆ¶åˆ‡åˆ†æˆå­—å¹•è¡Œ
4. å°‡åˆ‡åˆ†å¥½çš„å­—å¹•è¡Œèˆ‡å°é½Šå¾Œçš„æ™‚é–“æˆ³åˆä½µï¼Œç”¢ç”Ÿ SRT
"""

import os
import sys
import json
import re
import difflib
import subprocess
from pathlib import Path
from dotenv import load_dotenv
# from faster_whisper import WhisperModel # å·²ç§»é™¤
from openai import OpenAI
from opencc import OpenCC

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šå¸¸æ•¸
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = "gpt-4o-mini"
OPENAI_TEMPERATURE = 0.3
# WHISPER_MODEL_SIZE = "medium"  # å·²æ£„ç”¨ï¼ŒAPI å›ºå®šä½¿ç”¨ whisper-1

# æª”æ¡ˆå‘½åç´„å®š
AVATAR_FILENAME = "avatar_full.mp4"
EXTRACTED_AUDIO_FILENAME = "_extracted_audio.mp3"  # å¾ avatar æå–çš„éŸ³è»Œ
SCRIPT_FILENAME = "full_script.txt"
SUBTITLE_FILENAME = "full_subtitle.srt"

if not OPENAI_API_KEY:
    print("âŒ éŒ¯èª¤ï¼šæœªè¨­å®š OPENAI_API_KEY")
    sys.exit(1)

client = OpenAI(api_key=OPENAI_API_KEY)
# åˆå§‹åŒ–ç¹ç°¡è½‰æ› (é›–ä¸»è¦ä¾è³´é€å­—ç¨¿ï¼Œä½†åœ¨æŸæ­¤å­—ä¸²è™•ç†ä»å¯èƒ½ç”¨åˆ°)
cc = OpenCC('s2t')


# ============================================================
# Step 3 Prompt: æ–‡å­—åˆ‡åˆ†ï¼ˆè·Ÿéš¨åŸç¨¿æ®µè½çµæ§‹ + ç´”å­—æ•¸è¦å‰‡ï¼‰
# ============================================================
SEGMENTATION_PROMPT = """ä½ æ˜¯å°ˆæ¥­çš„å­—å¹•è£½ä½œå“¡ã€‚ä½ çš„ä»»å‹™æ˜¯å°‡æ ¡æ­£å¾Œçš„æ–‡å­—åˆ‡åˆ†æˆé©åˆå­—å¹•é¡¯ç¤ºçš„æ®µè½ã€‚

## æ–·å¥é‚è¼¯ï¼ˆéå¸¸é‡è¦ï¼Œè«‹åš´æ ¼éµå®ˆï¼‰

### è¦å‰‡ 1ï¼šå°Šé‡åŸç¨¿çš„æ®µè½çµæ§‹
- åŸç¨¿ä¸­çš„æ¯ä¸€å€‹æ®µè½ï¼ˆä»¥æ›è¡Œåˆ†éš”ï¼‰æ˜¯ç¨ç«‹çš„è™•ç†å–®ä½
- æ®µè½èˆ‡æ®µè½ä¹‹é–“æ˜¯è‡ªç„¶çš„åˆ†éš”é»ï¼Œ**å¿…é ˆæ›è¡Œ**

### è¦å‰‡ 2ï¼š18 å­—åŸå‰‡ï¼ˆä¸å«æ¨™é»ï¼‰
- è¨ˆç®—å­—æ•¸æ™‚ï¼Œ**å¿½ç•¥** æ¨™é»ç¬¦è™Ÿï¼ˆï¼Œã€‚ï¼Ÿï¼ï¼šï¼›ã€Œã€ç­‰ï¼‰ï¼Œåªè¨ˆç®—**åœ‹å­—/è‹±æ–‡å­—æ¯/æ•¸å­—**
- å¦‚æœä¸€æ®µæ–‡å­—çš„**ç´”å­—æ•¸ â‰¤ 18**ï¼š**ä¿æŒå®Œæ•´ï¼Œä¸æ‹†åˆ†**
- å¦‚æœä¸€æ®µæ–‡å­—çš„**ç´”å­—æ•¸ > 18**ï¼š**å¿…é ˆæ‹†åˆ†**

### è¦å‰‡ 3ï¼šæ‹†åˆ†ç­–ç•¥
- å¦‚æœå¿…é ˆæ‹†åˆ†ï¼Œå„ªå…ˆåœ¨ **é€—è™Ÿï¼ˆï¼Œï¼‰ã€é “è™Ÿï¼ˆã€ï¼‰** å¾Œé¢æ–·é–‹
- å¦‚æœæ²’æœ‰æ¨™é»å¯æ–·ï¼Œå‰‡åœ¨è©èªé‚Šç•Œæ–·é–‹
- çµ•å°ä¸è¦åœ¨è©èªä¸­é–“æ–·é–‹

## ç¯„ä¾‹

### åŸç¨¿
```
ç•¶é¢¨åœä¸‹ä¾†çš„æ™‚å€™ï¼Œèª°æœƒæœ€å…ˆæ‰ä¸‹ä¾†æ‘”æ­»ï¼Ÿ
```
å­—æ•¸åˆ†æï¼šã€Œç•¶é¢¨åœä¸‹ä¾†çš„æ™‚å€™èª°æœƒæœ€å…ˆæ‰ä¸‹ä¾†æ‘”æ­»ã€å…± 18 å€‹åœ‹å­—ã€‚
åˆ¤æ–·ï¼šâ‰¤ 18 å­—ï¼Œä¸æ‹†åˆ†ã€‚

### è¼¸å‡º
```
ç•¶é¢¨åœä¸‹ä¾†çš„æ™‚å€™ï¼Œèª°æœƒæœ€å…ˆæ‰ä¸‹ä¾†æ‘”æ­»ï¼Ÿ
```

### åŸç¨¿
```
ä»Šå¤©è¦è·Ÿè¦ªæ„›çš„ KQ æœ‹å‹å€‘èŠçš„é€™é–“å…¬å¸ï¼Œæœ€è¿‘å¯æ˜¯ç«™åœ¨é¢¨å£ä¸Šçš„è¶…ç´šå·¨æ˜Ÿ
```
å­—æ•¸åˆ†æï¼šå…± 30+ å€‹åœ‹å­—ï¼Œè¶…é 18ï¼Œéœ€æ‹†åˆ†ã€‚

### è¼¸å‡º
```
ä»Šå¤©è¦è·Ÿè¦ªæ„›çš„ KQ æœ‹å‹å€‘èŠçš„é€™é–“å…¬å¸ï¼Œ
æœ€è¿‘å¯æ˜¯ç«™åœ¨é¢¨å£ä¸Šçš„è¶…ç´šå·¨æ˜Ÿ
```

## è¼¸å‡ºæ ¼å¼
- æ¯è¡Œä¸€æ®µå­—å¹•æ–‡å­—
- ä¸è¦è¼¸å‡ºç·¨è™Ÿæˆ–æ™‚é–“æˆ³
- åªè¼¸å‡ºç´”æ–‡å­—
- ç¢ºä¿æ˜¯ç¹é«”ä¸­æ–‡"""


# ============================================================
# å·¥å…·å‡½æ•¸
# ============================================================
def normalize_path(input_path: str) -> Path:
    input_path = input_path.strip().strip('"').strip("'")
    return Path(input_path).expanduser().resolve()

def format_timestamp(seconds: float) -> str:
    """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼ (HH:MM:SS,mmm)"""
    millis = int((seconds % 1) * 1000)
    seconds = int(seconds)
    minutes = seconds // 60
    hours = minutes // 60
    minutes %= 60
    seconds %= 60
    return f"{hours:02}:{minutes:02}:{seconds:02},{millis:03}"

def save_srt(subtitles: list, output_path: Path):
    """å„²å­˜ SRT æª”æ¡ˆ"""
    with open(output_path, "w", encoding="utf-8") as f:
        for i, sub in enumerate(subtitles, 1):
            start = format_timestamp(sub["start"])
            end = format_timestamp(sub["end"])
            text = sub["text"]
            f.write(f"{i}\n{start} --> {end}\n{text}\n\n")
    print(f"âœ… æˆåŠŸï¼å­—å¹•å·²å„²å­˜è‡³ï¼š{output_path}")
    print(f"   å…± {len(subtitles)} è¡Œå­—å¹•")

def load_script(script_path: Path) -> str:
    """è®€å–ä¸¦æ¨™æº–åŒ–é€å­—ç¨¿ï¼ˆå‡è¨­å·²æ˜¯ç¹é«”ä¸­æ–‡ï¼Œä¸åšè½‰æ›ï¼‰"""
    if not script_path.exists():
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°é€å­—ç¨¿ {script_path}")
        sys.exit(1)
    
    with open(script_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    # çµ±ä¸€æ›è¡Œç¬¦ï¼ˆä¸åšç°¡ç¹è½‰æ›ï¼Œä¿ç•™åŸå§‹ç”¨å­—ï¼‰
    content = content.replace("\r\n", "\n").replace("\r", "\n")
    return content


def extract_audio_from_video(video_path: Path, output_path: Path) -> Path:
    """
    å¾ Avatar å½±ç‰‡æå–éŸ³è»Œä¾› Whisper ä½¿ç”¨
    ç¢ºä¿å­—å¹•æ™‚é–“æˆ³èˆ‡ Avatar å°å˜´å®Œå…¨ä¸€è‡´ï¼ˆSingle Source of Truthï¼‰
    """
    print("\nğŸ”Š å¾ Avatar å½±ç‰‡æå–éŸ³è»Œ...")
    
    result = subprocess.run([
        'ffmpeg', '-y',
        '-i', str(video_path),
        '-vn',  # ä¸è¦å½±åƒ
        '-acodec', 'libmp3lame',
        '-q:a', '2',  # é«˜å“è³ª
        str(output_path)
    ], capture_output=True, text=True)
    
    if result.returncode != 0:
        print(f"âš ï¸  FFmpeg è­¦å‘Šï¼š{result.stderr[-500:] if result.stderr else 'unknown'}")
    
    print(f"   âœ… éŸ³è»Œæå–å®Œæˆï¼š{output_path}")
    return output_path

# ============================================================
# æ ¸å¿ƒæ­¥é©Ÿ
# ============================================================

def step1_transcribe_whisper(audio_path: Path) -> list:
    """Step 1: ä½¿ç”¨ OpenAI Whisper API é€²è¡ŒèªéŸ³è¾¨è­˜ï¼ˆç²å–å­—ç´šæ™‚é–“æˆ³ï¼‰"""
    print("ğŸš€ é–‹å§‹ Step 1: Whisper API èªéŸ³è¾¨è­˜...")
    print("   æ­£åœ¨ä¸Šå‚³éŸ³è¨Šè‡³ OpenAI...")
    
    try:
        with open(audio_path, "rb") as audio_file:
            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="zh",
                response_format="verbose_json",
                timestamp_granularities=["word"]
            )
        
        # API å›å‚³çš„æ˜¯ç‰©ä»¶ï¼Œéœ€è¦è½‰ç‚ºæˆ‘å€‘éœ€è¦çš„æ ¼å¼
        # response.words æ˜¯ä¸€å€‹ list of objects (word, start, end)
        
        print(f"   API å›å‚³æˆåŠŸ (Duration: {response.duration:.2f}s)")
        
        word_timestamps = []
        if hasattr(response, 'words'):
            for word_obj in response.words:
                word_timestamps.append({
                    "word": cc.convert(word_obj.word.strip()),
                    "start": word_obj.start,
                    "end": word_obj.end
                })
        else:
            # Fallback (é›–ä¸å¤ªå¯èƒ½ï¼Œè‹¥æ²’ words åªæœ‰ text)
            print("   âš ï¸  è­¦å‘Šï¼šAPI æœªå›å‚³è©³ç´°å­—ç´šæ™‚é–“æˆ³")
        
        print(f"   âœ… å–å¾— {len(word_timestamps)} å€‹å­—ç´šæ™‚é–“æˆ³")
        return word_timestamps
        
    except Exception as e:
        print(f"âŒ Whisper API è¾¨è­˜å¤±æ•—ï¼š{e}")
        sys.exit(1)

def step2_force_alignment(whisper_timestamps: list, full_script: str) -> list:
    """Step 2: Force Alignment (Python)
    å°‡ Whisper çš„æ™‚é–“æˆ³å¼·åˆ¶å°é½Šåˆ°æ­£ç¢ºçš„é€å­—ç¨¿ä¸Šã€‚
    """
    print("ğŸ”§ Step 2: åŸ·è¡Œ Force Alignment (æ™‚é–“æˆ³å°é½Š)...")
    
    # ç‚ºäº†æœ€ç²¾ç¢ºï¼Œæˆ‘å€‘æ¡ç”¨ã€Œå­—å…ƒç´šã€æ¯”å°
    # 1. æº–å‚™ Whisper çš„å­—å…ƒåˆ—è¡¨ (åŒ…å«æ™‚é–“)
    whisper_chars = []
    for w in whisper_timestamps:
        for char in w["word"]:
            whisper_chars.append({"char": char, "start": w["start"], "end": w["end"]})
            
    # 2. æº–å‚™ Script çš„å­—å…ƒåˆ—è¡¨ (ä¸å«æ›è¡Œï¼Œä»¥ä¾¿é€²è¡Œåºåˆ—æ¯”å°)
    # ä½†æˆ‘å€‘éœ€è¦ä¿ç•™æ›è¡Œç¬¦çš„ã€Œä½ç½®æ„Ÿã€ï¼Œæˆ–è€…åœ¨å°é½Šå¾Œèƒ½æ˜ å°„å›å»ã€‚
    # æœ€ç°¡å–®çš„æ–¹æ³•ï¼šåªå°é½Šå¯¦é«”å­—å…ƒï¼Œæ¨™é»ç¬¦è™Ÿè¦–ç‚ºå­—å…ƒä¹‹ä¸€ã€‚
    # full_script åŒ…å«å…¨éƒ¨æ­£ç¢ºçš„å­—å’Œæ¨™é»
    
    script_chars = list(full_script.replace("\n", "")) 
    
    whisper_str = "".join([x["char"] for x in whisper_chars])
    script_str = "".join(script_chars)
    
    # 3. ä½¿ç”¨ difflib é€²è¡Œåºåˆ—æ¯”å°
    # autojunk=False å¾ˆé‡è¦ï¼Œé¿å…é•·å­—ä¸²è¢«ç•¶ä½œåƒåœ¾å¿½ç•¥
    matcher = difflib.SequenceMatcher(None, whisper_str, script_str, autojunk=False)
    
    aligned_results = []
    
    # è¨˜éŒ„æ­£ç¢ºæ–‡æœ¬ç›®å‰è™•ç†åˆ°çš„æ™‚é–“é€²åº¦
    current_time = 0.0
    if whisper_chars:
        current_time = whisper_chars[0]["start"]
        
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        # tag: replace, delete, insert, equal
        # whisper_str[i1:i2] vs script_str[j1:j2]
        
        if tag == 'equal':
            # å®Œå…¨åŒ¹é…ï¼šç›´æ¥ä½¿ç”¨ Whisper çš„æ™‚é–“
            # å°æ–¼æ¨™é»ç¬¦è™Ÿï¼Œå¦‚æœ Whisper ä¹Ÿæœ‰è½åˆ°(æˆ–è¼¸å‡º)ï¼Œæ™‚é–“ä¹Ÿæœƒå°
            for k in range(j2 - j1):
                w_char = whisper_chars[i1 + k]
                aligned_results.append({
                    "char": script_str[j1 + k],
                    "start": w_char["start"],
                    "end": w_char["end"]
                })
                current_time = w_char["end"]
                
        elif tag == 'replace':
            # æ›¿æ›ï¼šWhisper è½éŒ¯äº†ï¼ŒScript æ˜¯å°çš„
            # å°‡ Whisper é€™æ®µçš„æ™‚é–“å€é–“ï¼Œå¹³å‡åˆ†é…çµ¦ Script é€™æ®µçš„å­—
            if i2 > i1:
                start_t = whisper_chars[i1]["start"]
                end_t = whisper_chars[i2-1]["end"]
            else:
                start_t = current_time
                end_t = current_time 
                
            duration = end_t - start_t
            num_script_chars = j2 - j1
            
            if num_script_chars > 0:
                char_duration = duration / num_script_chars
                for k in range(num_script_chars):
                    aligned_results.append({
                        "char": script_str[j1 + k],
                        "start": start_t + (k * char_duration),
                        "end": start_t + ((k + 1) * char_duration)
                    })
            current_time = end_t
            
        elif tag == 'delete':
            # åˆªé™¤ï¼šWhisper å¤šè½åˆ°äº† (hallucination)ï¼ŒScript æ²’æœ‰
            # ç›´æ¥å¿½ç•¥é€™æ®µ Whisper çš„æ™‚é–“
            if i2 > i1:
                current_time = whisper_chars[i2-1]["end"]
            
        elif tag == 'insert':
            # æ’å…¥ï¼šWhisper æ²’è½åˆ°ï¼Œä½† Script æœ‰ (æ¼å­—)
            # é€™äº›å­—æ²’æœ‰å°æ‡‰çš„æ™‚é–“ï¼Œæš«æ™‚æ“ åœ¨ current_time
             for k in range(j2 - j1):
                aligned_results.append({
                    "char": script_str[j1 + k],
                    "start": current_time,
                    "end": current_time
                })

    print(f"   âœ… Force Alignment å®Œæˆ (å…± {len(aligned_results)} å€‹å­—å…ƒ)")
    return aligned_results

def step3_segment_text(transcript: str, client: OpenAI) -> list:
    """Step 3: GPT æ–‡å­—åˆ‡åˆ†ï¼ˆæ ¹æ“šåŸç¨¿æ®µè½çµæ§‹ï¼‰ - åªæœ‰åˆ‡åˆ†ï¼Œä¸æ¶‰åŠæ™‚é–“"""
    print("âœ‚ï¸  Step 3: GPT æ–‡å­—åˆ‡åˆ†...")
    
    user_prompt = f"""è«‹æ ¹æ“šåŸç¨¿çš„æ®µè½çµæ§‹ï¼Œå°‡ä»¥ä¸‹æ–‡å­—åˆ‡åˆ†æˆå­—å¹•æ®µè½ï¼š

## åŸç¨¿
{transcript}

è«‹è¼¸å‡ºåˆ‡åˆ†å¾Œçš„ç´”æ–‡å­—ï¼ˆæ¯è¡Œä¸€æ®µï¼‰ã€‚"""

    try:
        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            temperature=OPENAI_TEMPERATURE,
            messages=[
                {"role": "system", "content": SEGMENTATION_PROMPT},
                {"role": "user", "content": user_prompt}
            ]
        )
        
        result = response.choices[0].message.content
        result = re.sub(r'^```\n?', '', result)
        result = re.sub(r'\n?```$', '', result)
        
        lines = [line.strip() for line in result.strip().split('\n') if line.strip()]
        
        print(f"   âœ… åˆ‡åˆ†å®Œæˆ (tokens: {response.usage.total_tokens})")
        print(f"   ğŸ“ åˆ‡åˆ†ç‚º {len(lines)} è¡Œ")
        return lines
        
    except Exception as e:
        print(f"âŒ API éŒ¯èª¤ï¼š{e}")
        sys.exit(1)

def step4_align_timestamps(subtitle_lines: list, aligned_chars: list) -> list:
    """Step 4: å°‡åˆ‡åˆ†å¥½çš„å­—å¹•è¡Œèˆ‡æ™‚é–“æˆ³å°é½Š
    
    æ”¹é€²ç‰ˆï¼š
    1. æ‰¾ä¸åˆ°ç²¾ç¢ºåŒ¹é…æ™‚ï¼Œä½¿ç”¨ã€Œç•¶å‰æ™‚é–“ã€ç¹¼çºŒæ¨é€²ï¼ˆä¸æœƒæ¼å­—å¹•ï¼‰
    2. å®Œæˆå¾Œæª¢æŸ¥è¦†è“‹ç‡ï¼Œä½æ–¼ 80% æ™‚è­¦å‘Š
    """
    print("â±ï¸  Step 4: Python å­—å¹•å°é½Š...")
    
    final_subtitles = []
    char_idx = 0
    total_chars = len(aligned_chars)
    
    # çµ±è¨ˆç”¨
    matched_count = 0
    fallback_count = 0
    total_script_chars = sum(len(line.replace("\n", "").replace("\r", "")) for line in subtitle_lines)
    
    # å–å¾—åŸºæº–æ™‚é–“ï¼ˆç”¨æ–¼ fallbackï¼‰
    current_time = aligned_chars[0]["start"] if aligned_chars else 0.0
    last_end_time = aligned_chars[-1]["end"] if aligned_chars else 0.0
    
    for line in subtitle_lines:
        line_clean = line.replace("\n", "").replace("\r", "")
        if not line_clean:
            continue
            
        start_time = None
        end_time = None
        
        # å°‹æ‰¾é€™è¡Œå­—å¹•çš„é–‹å§‹èˆ‡çµæŸæ™‚é–“
        for char in line_clean:
            # è²ªå©ªåŒ¹é…ï¼šåœ¨ aligned_chars ä¸­å°‹æ‰¾ä¸‹ä¸€å€‹åŒ¹é…çš„å­—å…ƒ
            found = False
            search_window = 100  # ä¸è¦ç„¡é™å¾€å¾Œæ‰¾
            
            for k in range(min(search_window, total_chars - char_idx)):
                if aligned_chars[char_idx + k]["char"] == char:
                    found_idx = char_idx + k
                    item = aligned_chars[found_idx]
                    
                    if start_time is None:
                        start_time = item["start"]
                    
                    # æŒçºŒæ›´æ–° end_time ç›´åˆ°æ•´å¥çµæŸ
                    end_time = item["end"]
                    current_time = item["end"]
                    
                    # æ›´æ–°å…¨åŸŸæŒ‡é‡
                    char_idx = found_idx + 1
                    found = True
                    matched_count += 1
                    break
            
            if not found:
                # ã€ä¿®å¾©å»¶é²ã€‘æ‰¾ä¸åˆ°ç²¾ç¢ºåŒ¹é…æ™‚ï¼š
                # 1. ä½¿ç”¨ç•¶å‰ä½ç½®çš„æ™‚é–“ï¼ˆè€Œéé™³èˆŠçš„ current_timeï¼‰
                # 2. æ¨é€² char_idx é¿å…å¡ä½
                fallback_count += 1
                
                if char_idx < total_chars:
                    # ä½¿ç”¨ç•¶å‰ä½ç½®çš„æ™‚é–“
                    item = aligned_chars[char_idx]
                    if start_time is None:
                        start_time = item["start"]
                    end_time = item["end"]
                    current_time = item["end"]
                    # ã€é—œéµä¿®å¾©ã€‘æ¨é€²æŒ‡é‡ï¼Œé¿å…å»¶é²ç´¯ç©
                    char_idx += 1
                else:
                    # å·²ç¶“åˆ°é”æœ«å°¾ï¼Œä½¿ç”¨æœ€å¾Œçš„æ™‚é–“
                    if start_time is None:
                        start_time = current_time
                    end_time = current_time
        
        # ã€æ”¹é€²ã€‘å³ä½¿åªæœ‰ fallback æ™‚é–“ï¼Œä¹Ÿè¦ç”¢ç”Ÿå­—å¹•ï¼ˆä¸æœƒæ¼ï¼‰
        if start_time is not None:
            # ç¢ºä¿ end_time è‡³å°‘æ¯” start_time å¤§ä¸€é»é»
            if end_time <= start_time:
                end_time = start_time + 0.5
            
            final_subtitles.append({
                "start": start_time,
                "end": end_time,
                "text": line
            })
    
    # ã€æ”¹é€²ã€‘è¦†è“‹ç‡æª¢æŸ¥
    if total_script_chars > 0:
        coverage = matched_count / total_script_chars
        print(f"   ğŸ“Š å°é½Šè¦†è“‹ç‡ï¼š{coverage:.1%} ({matched_count}/{total_script_chars} å­—å…ƒ)")
        
        if coverage < 0.8:
            print(f"   âš ï¸  è­¦å‘Šï¼šè¦†è“‹ç‡ä½æ–¼ 80%ï¼Œå­—å¹•æ™‚é–“å¯èƒ½ä¸å¤ ç²¾ç¢ºï¼")
            print(f"   âš ï¸  å»ºè­°æª¢æŸ¥é€å­—ç¨¿èˆ‡éŸ³è¨Šæ˜¯å¦åŒ¹é…ã€‚")
        
        if fallback_count > 0:
            print(f"   â„¹ï¸  ä½¿ç”¨ fallback æ™‚é–“çš„å­—å…ƒæ•¸ï¼š{fallback_count}")
    
    print("   âœ… å°é½Šå®Œæˆ")
    return final_subtitles

# ============================================================
# ä¸»ç¨‹å¼
# ============================================================
def main():
    print("============================================================")
    print("ğŸ™ï¸  AI è‡ªå‹•å­—å¹•ç”Ÿæˆå™¨ V9 (Avatar Audio ç‰ˆ)")
    print("   Avatar éŸ³è»Œæå– -> Whisper -> Force Align -> GPT -> SRT")
    print("============================================================")
    
    # é è¨­è·¯å¾‘ (æ–¹ä¾¿æ¸¬è©¦)
    default_path = "/Users/a01-0218-0512/Downloads/nvdia_jay"
    user_input = input(f"ğŸ“‚ è«‹è¼¸å…¥ç´ æè³‡æ–™å¤¾è·¯å¾‘ (é è¨­: {default_path})ï¼š").strip()
    
    if not user_input:
        folder_path = default_path
    else:
        folder_path = user_input.strip('"').strip("'")

    work_dir = normalize_path(folder_path)
    if not work_dir.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è·¯å¾‘ï¼š{work_dir}")
        return

    print(f"ğŸ“ å·¥ä½œç›®éŒ„ï¼š{work_dir}")
    
    avatar_path = work_dir / AVATAR_FILENAME
    script_path = work_dir / SCRIPT_FILENAME
    output_path = work_dir / SUBTITLE_FILENAME
    extracted_audio_path = work_dir / EXTRACTED_AUDIO_FILENAME
    
    # æª¢æŸ¥å¿…è¦æª”æ¡ˆ
    if not avatar_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ° Avatar å½±ç‰‡ï¼š{avatar_path}")
        return
    if not script_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°é€å­—ç¨¿ï¼š{script_path}")
        return

    # å¾ Avatar å½±ç‰‡æå–éŸ³è»Œï¼ˆSingle Source of Truthï¼‰
    extract_audio_from_video(avatar_path, extracted_audio_path)

    # Loading Script
    full_script = load_script(script_path)
    print(f"ğŸ“ é€å­—ç¨¿é•·åº¦ï¼š{len(full_script)} å­—")

    # Step 1: Whisperï¼ˆä½¿ç”¨å¾ Avatar æå–çš„éŸ³è»Œï¼‰
    whisper_timestamps = step1_transcribe_whisper(extracted_audio_path)
    
    # ã€åµéŒ¯ã€‘å„²å­˜ Step 1 çµæœ
    step1_output_path = work_dir / "_debug_step1_whisper.json"
    with open(step1_output_path, "w", encoding="utf-8") as f:
        json.dump(whisper_timestamps, f, ensure_ascii=False, indent=2)
    print(f"   ğŸ’¾ Step 1 çµæœå·²å„²å­˜ï¼š{step1_output_path}")

    
    # Step 2: Force Alignment
    aligned_chars = step2_force_alignment(whisper_timestamps, full_script)
    
    # ã€åµéŒ¯ã€‘å„²å­˜ Step 2 çµæœ
    step2_output_path = work_dir / "_debug_step2_alignment.json"
    with open(step2_output_path, "w", encoding="utf-8") as f:
        json.dump(aligned_chars, f, ensure_ascii=False, indent=2)
    print(f"   ğŸ’¾ Step 2 çµæœå·²å„²å­˜ï¼š{step2_output_path}")
    
    # Step 3: Segmentation
    subtitle_lines = step3_segment_text(full_script, client)
    
    # Step 4: Final Alignment
    final_subtitles = step4_align_timestamps(subtitle_lines, aligned_chars)
    
    # Save
    save_srt(final_subtitles, output_path)
    
    # æ¸…ç†æš«å­˜çš„æå–éŸ³æª”
    if extracted_audio_path.exists():
        extracted_audio_path.unlink()
        print("   ğŸ—‘ï¸  å·²æ¸…ç†æš«å­˜éŸ³æª”")
    
    print("============================================================")

if __name__ == "__main__":
    main()
