"""
å­—å¹•ç”Ÿæˆæœå‹™
å¾ generate_subtitles.py æŠ½é›¢çš„æ ¸å¿ƒæ¥­å‹™é‚è¼¯
"""

import os
import re
import json
import difflib
import subprocess
from pathlib import Path
from opencc import OpenCC

from integrations.openai_client import get_openai_client
from integrations.openrouter_client import get_openrouter_client


class SubtitleService:
    """
    å­—å¹•ç”Ÿæˆæœå‹™
    
    æµç¨‹ï¼š
    1. å¾ Avatar å½±ç‰‡æå–éŸ³è»Œ
    2. Whisper èªéŸ³è¾¨è­˜ï¼ˆå­—ç´šæ™‚é–“æˆ³ï¼‰
    3. Force Alignmentï¼ˆDTW å°é½Šä¿®æ­£éŒ¯å­—ï¼‰
    4. AI æ™ºæ…§æ–·å¥
    5. æ™‚é–“æˆ³å°é½Šç”¢ç”Ÿ SRT
    """
    
    # æª”æ¡ˆå‘½åç´„å®š
    AVATAR_FILENAME = "avatar_full.mp4"
    EXTRACTED_AUDIO_FILENAME = "_extracted_audio.mp3"
    SCRIPT_FILENAME = "full_script.txt"
    SUBTITLE_FILENAME = "full_subtitle.srt"
    
    # Claude å­—å¹•åˆ‡ç‰‡æç¤ºè©ï¼ˆè²ªå©ªåŒ¹é… + è¦–è¦ºå¹³è¡¡ï¼‰
    SEGMENTATION_PROMPT = """ä½ æ˜¯å°ˆæ¥­çš„å­—å¹•è£½ä½œå“¡ã€‚è¼¸å…¥çš„æ–‡å­—å·²ç¶“ç¶“éç¨‹å¼é è™•ç†ï¼Œæ¸…é™¤äº†æ‰€æœ‰ç‰¹æ®Šç¬¦è™Ÿï¼Œåƒ…ä¿ç•™å¿…è¦çš„å…¨å½¢æ¨™é»ï¼ˆï¼Œã€‚ï¼Ÿï¼ï¼‰ã€‚

ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šã€Œé•·åº¦é™åˆ¶ã€å°‡æ–‡å­—æ•´ç†ç‚ºå­—å¹•ï¼Œä¸¦åš´æ ¼éµå®ˆã€Œéå¿…è¦ä¸æ‹†åˆ†ã€çš„åŸå‰‡ã€‚

## æ ¸å¿ƒé‚è¼¯ï¼ˆç”±ä¸Šè€Œä¸‹åŸ·è¡Œï¼‰

### è¦å‰‡ 1ï¼šè²ªå©ªåŒ¹é…ï¼ˆGreedy Strategyï¼‰â€”â€” æœ€é‡è¦ï¼
- **èƒ½ä¸æ›è¡Œï¼Œå°±çµ•å°ä¸æ›è¡Œã€‚**
- åªè¦è©²æ®µè½çš„ç¸½é•·åº¦ï¼ˆå«æ¨™é»ï¼‰ **â‰¤ 18 å€‹å…¨å½¢å­—å…ƒ**ï¼Œè«‹ç›´æ¥ä½œç‚ºä¸€è¡Œè¼¸å‡ºï¼Œ**å¿½ç•¥**ä¸­é–“çš„é€—è™Ÿã€‚
- åªæœ‰ç•¶å­—æ•¸ **> 18 å­—** æ™‚ï¼Œæ‰è§¸ç™¼æ‹†åˆ†é‚è¼¯ã€‚

### è¦å‰‡ 2ï¼šæ‹†åˆ†ç­–ç•¥ï¼ˆåƒ…åœ¨è¶…é 18 å­—æ™‚åŸ·è¡Œï¼‰
- ç•¶å¿…é ˆæ‹†åˆ†æ™‚ï¼Œè«‹éµå¾ªã€Œ**è¦–è¦ºå¹³è¡¡**ã€åŸå‰‡ï¼Œå°‡é•·å¥åˆ‡åˆ†ç‚ºé•·åº¦ç›¸è¿‘çš„å…©è¡Œï¼ˆä¾‹å¦‚ 30 å­—åˆ‡æˆ 15+15ï¼Œè€Œä¸æ˜¯ 20+10ï¼‰ã€‚
- **åˆ‡åˆ†é»å„ªå…ˆç´š**ï¼š
    1.  å„ªå…ˆåœ¨æ¨™é»ç¬¦è™Ÿï¼ˆï¼Œï¼‰å¾Œæ–¹åˆ‡åˆ†ã€‚
    2.  è‹¥ç„¡æ¨™é»ï¼Œåœ¨èªæ„åœé “è™•ï¼ˆè©çµ„é‚Šç•Œï¼‰åˆ‡åˆ†ã€‚
- **å­¤å…’å­—é˜²è­·**ï¼šæ‹†åˆ†å¾Œçš„ä»»ä½•ä¸€è¡Œï¼Œä¸å¯å°‘æ–¼ 5 å€‹å­—ã€‚

## ç¯„ä¾‹å°ç…§

### åŸç¨¿ï¼ˆçŸ­å¥ï¼‰
`ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œæˆ‘å€‘å»æ•£æ­¥å§ã€‚`
ï¼ˆå­—æ•¸ 13 å­—ï¼Œæœªè¶…é 18ï¼‰

#### âŒ éŒ¯èª¤è¼¸å‡ºï¼ˆéåº¦æ‹†åˆ†ï¼‰
ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œ
æˆ‘å€‘å»æ•£æ­¥å§ã€‚

#### âœ… æ­£ç¢ºè¼¸å‡ºï¼ˆè²ªå©ªæ¨¡å¼ï¼‰
ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œæˆ‘å€‘å»æ•£æ­¥å§ã€‚

---

### åŸç¨¿ï¼ˆé•·å¥ï¼‰
`Oracle ç”²éª¨æ–‡é€™å®¶è®“äººåˆæ„›åˆæ¨çš„è»Ÿé«”å·¨é ­ï¼Œçµ‚æ–¼ç™¼å¸ƒäº†æœ€æ–°è²¡å ±ã€‚`
ï¼ˆå­—æ•¸ 29 å­—ï¼Œè¶…é 20ï¼Œå¿…é ˆæ‹†åˆ†ï¼‰

#### âŒ éŒ¯èª¤è¼¸å‡ºï¼ˆæ­»æ¿æ‹†åˆ†ï¼Œå°è‡´ç¬¬äºŒè¡ŒéçŸ­ï¼‰
Oracle ç”²éª¨æ–‡é€™å®¶è®“äººåˆæ„›åˆæ¨çš„è»Ÿé«”å·¨é ­ï¼Œ
çµ‚æ–¼ç™¼å¸ƒäº†æœ€æ–°è²¡å ±ã€‚
ï¼ˆè§£é‡‹ï¼šç¬¬ä¸€è¡Œ 19 å­—ï¼Œç¬¬äºŒè¡Œåƒ… 10 å­—ï¼Œé ­é‡è…³è¼•ï¼‰

#### âœ… æ­£ç¢ºè¼¸å‡ºï¼ˆè¦–è¦ºå¹³è¡¡ï¼‰
Oracle ç”²éª¨æ–‡é€™å®¶è®“äººåˆæ„›åˆæ¨çš„
è»Ÿé«”å·¨é ­ï¼Œçµ‚æ–¼ç™¼å¸ƒäº†æœ€æ–°è²¡å ±ã€‚
ï¼ˆè§£é‡‹ï¼šç´„ 14+15 å­—ï¼Œè¦–è¦ºå¹³è¡¡ï¼Œä¸”æ²’æœ‰åˆ‡æ–·ã€Œè»Ÿé«”å·¨é ­ã€ï¼‰

## è¼¸å‡ºæ ¼å¼
- åƒ…è¼¸å‡ºè™•ç†å¾Œçš„æ–‡å­—ï¼Œæ¯è¡Œä¸€å¥ã€‚
- åš´ç¦è¼¸å‡ºä»»ä½•è§£é‡‹ã€ç·¨è™Ÿæˆ– markdown æ¨™è¨˜ã€‚"""
    
    def __init__(self):
        self.openai_client = get_openai_client()
        self.openrouter_client = get_openrouter_client()
        self.cc = OpenCC('s2t')
    
    def generate(self, folder_path: Path, debug: bool = True) -> Path:
        """
        ç”Ÿæˆå­—å¹•çš„ä¸»å…¥å£
        
        Args:
            folder_path: ç´ æè³‡æ–™å¤¾è·¯å¾‘
            debug: æ˜¯å¦å„²å­˜ä¸­é–“çµæœä¾›é™¤éŒ¯
            
        Returns:
            ç”Ÿæˆçš„ SRT æª”æ¡ˆè·¯å¾‘
        """
        folder_path = Path(folder_path)
        
        # æª”æ¡ˆè·¯å¾‘
        avatar_path = folder_path / self.AVATAR_FILENAME
        script_path = folder_path / self.SCRIPT_FILENAME
        output_path = folder_path / self.SUBTITLE_FILENAME
        extracted_audio_path = folder_path / self.EXTRACTED_AUDIO_FILENAME
        
        # é©—è­‰å¿…è¦æª”æ¡ˆ
        self._validate_files(avatar_path, script_path)
        
        print("============================================================")
        print("ğŸ™ï¸  å­—å¹•ç”Ÿæˆæœå‹™")
        print("   Avatar éŸ³è»Œæå– -> Whisper -> Force Align -> AI -> SRT")
        print("============================================================")
        print(f"ğŸ“ å·¥ä½œç›®éŒ„ï¼š{folder_path}")
        
        try:
            # Step 0: å¾ Avatar å½±ç‰‡æå–éŸ³è»Œ
            self._extract_audio(avatar_path, extracted_audio_path)
            
            # è¼‰å…¥é€å­—ç¨¿
            full_script = self._load_script(script_path)
            print(f"ğŸ“ åŸå§‹é€å­—ç¨¿é•·åº¦ï¼š{len(full_script)} å­—")
            
            # Step 0.5: ç¬¦è™Ÿæ¸…æ´—ï¼ˆç¢ºä¿ Step 2 å’Œ Step 3 ä½¿ç”¨ä¸€è‡´çš„æ–‡å­—ï¼‰
            sanitized_script = self._sanitize_script(full_script)
            print(f"ğŸ§¹ æ¸…æ´—å¾Œé€å­—ç¨¿é•·åº¦ï¼š{len(sanitized_script)} å­—")
            
            if debug:
                self._save_debug_text(folder_path / "_debug_sanitized_script.txt", [sanitized_script])
            
            # Step 1: Whisper èªéŸ³è¾¨è­˜
            whisper_timestamps = self._step1_transcribe_whisper(extracted_audio_path)
            
            if debug:
                self._save_debug_json(folder_path / "_debug_step1_whisper.json", whisper_timestamps)
            
            # Step 2: Force Alignmentï¼ˆä½¿ç”¨æ¸…æ´—å¾Œçš„é€å­—ç¨¿ï¼‰
            aligned_chars = self._step2_force_alignment(whisper_timestamps, sanitized_script)
            
            if debug:
                self._save_debug_json(folder_path / "_debug_step2_alignment.json", aligned_chars)
            
            # Step 3: Claude æ–‡å­—åˆ‡åˆ†ï¼ˆä½¿ç”¨æ¸…æ´—å¾Œçš„é€å­—ç¨¿ï¼‰
            subtitle_lines = self._step3_segment_text(sanitized_script)
            
            if debug:
                self._save_debug_text(folder_path / "_debug_step3_ai_segments.txt", subtitle_lines)
            
            # Step 4: æ™‚é–“æˆ³å°é½Š
            final_subtitles = self._step4_align_timestamps(subtitle_lines, aligned_chars)
            
            # å„²å­˜ SRT
            self._save_srt(final_subtitles, output_path)
            
            print("============================================================")
            
            return output_path
            
        finally:
            # æ¸…ç†æš«å­˜çš„æå–éŸ³æª”
            if extracted_audio_path.exists():
                extracted_audio_path.unlink()
                print("   ğŸ—‘ï¸  å·²æ¸…ç†æš«å­˜éŸ³æª”")
    
    def _validate_files(self, avatar_path: Path, script_path: Path):
        """é©—è­‰å¿…è¦æª”æ¡ˆå­˜åœ¨"""
        if not avatar_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ° Avatar å½±ç‰‡ï¼š{avatar_path}")
        if not script_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°é€å­—ç¨¿ï¼š{script_path}")
    
    def _extract_audio(self, video_path: Path, output_path: Path) -> Path:
        """å¾ Avatar å½±ç‰‡æå–éŸ³è»Œ"""
        print("\nğŸ”Š å¾ Avatar å½±ç‰‡æå–éŸ³è»Œ...")
        
        result = subprocess.run([
            'ffmpeg', '-y',
            '-i', str(video_path),
            '-vn',
            '-acodec', 'libmp3lame',
            '-q:a', '2',
            str(output_path)
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âš ï¸  FFmpeg è­¦å‘Šï¼š{result.stderr[-500:] if result.stderr else 'unknown'}")
        
        print(f"   âœ… éŸ³è»Œæå–å®Œæˆï¼š{output_path}")
        return output_path
    
    def _load_script(self, script_path: Path) -> str:
        """è®€å–ä¸¦æ¨™æº–åŒ–é€å­—ç¨¿"""
        with open(script_path, "r", encoding="utf-8") as f:
            content = f.read()
        content = content.replace("\r\n", "\n").replace("\r", "\n")
        return content
    
    def _sanitize_script(self, text: str) -> str:
        """
        ç¬¦è™Ÿæ¸…æ´—ï¼šç¢ºä¿ Alignment å’Œ Claude æ–·å¥ä½¿ç”¨ä¸€è‡´çš„æ–‡å­—
        
        æ¸…æ´—è¦å‰‡ï¼š
        1. åˆªé™¤ï¼šå¼•è™Ÿã€Œã€""ã€æ‹¬è™Ÿ()ã€æ›¸åè™Ÿã€Šã€‹
        2. æ›¿æ›ç‚ºé€—è™Ÿï¼šé “è™Ÿã€ã€åˆ†è™Ÿï¼›
        3. æ›¿æ›ç‚ºç©ºæ ¼ï¼šå†’è™Ÿï¼š
        4. åˆªé™¤ï¼šç ´æŠ˜è™Ÿâ€”â€”ã€çœç•¥è™Ÿâ€¦â€¦
        5. ä¸­è‹±æ–‡é–“åŠ ç©ºæ ¼
        """
        # 1. åˆªé™¤å¼•è™Ÿã€æ‹¬è™Ÿã€æ›¸åè™Ÿ
        text = re.sub(r'[ã€Œã€""()ã€Šã€‹]', '', text)
        
        # 2. é “è™Ÿã€åˆ†è™Ÿ â†’ é€—è™Ÿ
        text = text.replace('ã€', 'ï¼Œ').replace('ï¼›', 'ï¼Œ')
        
        # 3. å†’è™Ÿ â†’ ç©ºæ ¼
        text = text.replace('ï¼š', ' ')
        
        # 4. åˆªé™¤ç ´æŠ˜è™Ÿã€çœç•¥è™Ÿ
        text = re.sub(r'â€”â€”|â€¦â€¦|\.{3,}', '', text)
        
        # 5. ä¸­è‹±æ–‡é–“åŠ ç©ºæ ¼ï¼ˆè‹±æ–‡/æ•¸å­— â†” ä¸­æ–‡ï¼‰
        text = re.sub(r'([a-zA-Z0-9])([^\x00-\x7F\s])', r'\1 \2', text)
        text = re.sub(r'([^\x00-\x7F])([a-zA-Z0-9])', r'\1 \2', text)
        
        # æ¸…ç†å¤šé¤˜ç©ºæ ¼
        text = re.sub(r' +', ' ', text)
        
        return text
    
    def _step1_transcribe_whisper(self, audio_path: Path) -> list:
        """Step 1: Whisper èªéŸ³è¾¨è­˜"""
        print("ğŸš€ é–‹å§‹ Step 1: Whisper API èªéŸ³è¾¨è­˜...")
        print("   æ­£åœ¨ä¸Šå‚³éŸ³è¨Šè‡³ OpenAI...")
        
        response = self.openai_client.transcribe_audio(audio_path)
        
        print(f"   API å›å‚³æˆåŠŸ (Duration: {response.duration:.2f}s)")
        
        word_timestamps = []
        if hasattr(response, 'words'):
            for word_obj in response.words:
                word_timestamps.append({
                    "word": self.cc.convert(word_obj.word.strip()),
                    "start": word_obj.start,
                    "end": word_obj.end
                })
        else:
            print("   âš ï¸  è­¦å‘Šï¼šAPI æœªå›å‚³è©³ç´°å­—ç´šæ™‚é–“æˆ³")
        
        print(f"   âœ… å–å¾— {len(word_timestamps)} å€‹å­—ç´šæ™‚é–“æˆ³")
        return word_timestamps
    
    def _step2_force_alignment(self, whisper_timestamps: list, full_script: str) -> list:
        """Step 2: Force Alignment (DTW å°é½Š)"""
        print("ğŸ”§ Step 2: åŸ·è¡Œ Force Alignment (æ™‚é–“æˆ³å°é½Š)...")
        
        # æº–å‚™ Whisper çš„å­—å…ƒåˆ—è¡¨
        whisper_chars = []
        for w in whisper_timestamps:
            for char in w["word"]:
                whisper_chars.append({"char": char, "start": w["start"], "end": w["end"]})
        
        # æº–å‚™ Script çš„å­—å…ƒåˆ—è¡¨
        script_chars = list(full_script.replace("\n", ""))
        
        whisper_str = "".join([x["char"] for x in whisper_chars])
        script_str = "".join(script_chars)
        
        # ä½¿ç”¨ difflib é€²è¡Œåºåˆ—æ¯”å°
        matcher = difflib.SequenceMatcher(None, whisper_str, script_str, autojunk=False)
        
        aligned_results = []
        current_time = 0.0
        if whisper_chars:
            current_time = whisper_chars[0]["start"]
        
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'equal':
                for k in range(j2 - j1):
                    w_char = whisper_chars[i1 + k]
                    aligned_results.append({
                        "char": script_str[j1 + k],
                        "start": w_char["start"],
                        "end": w_char["end"]
                    })
                    current_time = w_char["end"]
                    
            elif tag == 'replace':
                if i2 > i1:
                    start_t = whisper_chars[i1]["start"]
                    end_t = whisper_chars[i2-1]["end"]
                else:
                    start_t = current_time
                    end_t = current_time
                    
                duration = end_t - start_t
                num_script_chars = j2 - j1
                
                if num_script_chars > 0:
                    char_duration = duration / num_script_chars
                    for k in range(num_script_chars):
                        aligned_results.append({
                            "char": script_str[j1 + k],
                            "start": start_t + (k * char_duration),
                            "end": start_t + ((k + 1) * char_duration)
                        })
                current_time = end_t
                
            elif tag == 'delete':
                if i2 > i1:
                    current_time = whisper_chars[i2-1]["end"]
                
            elif tag == 'insert':
                for k in range(j2 - j1):
                    aligned_results.append({
                        "char": script_str[j1 + k],
                        "start": current_time,
                        "end": current_time
                    })
        
        print(f"   âœ… Force Alignment å®Œæˆ (å…± {len(aligned_results)} å€‹å­—å…ƒ)")
        return aligned_results
    
    def _step3_segment_text(self, transcript: str) -> list:
        """Step 3: AI æ–‡å­—åˆ‡åˆ†"""
        print("âœ‚ï¸  Step 3: AI æ–‡å­—åˆ‡åˆ†...")
        
        user_prompt = f"""è«‹æ ¹æ“šåŸç¨¿çš„æ®µè½çµæ§‹ï¼Œå°‡ä»¥ä¸‹æ–‡å­—åˆ‡åˆ†æˆå­—å¹•æ®µè½ï¼š

## åŸç¨¿
{transcript}

è«‹è¼¸å‡ºåˆ‡åˆ†å¾Œçš„ç´”æ–‡å­—ï¼ˆæ¯è¡Œä¸€æ®µï¼‰ã€‚"""
        
        result = self.openrouter_client.chat_completion(
            system_prompt=self.SEGMENTATION_PROMPT,
            user_prompt=user_prompt
        )
        
        # æ¸…ç†çµæœ
        result = re.sub(r'^```\n?', '', result)
        result = re.sub(r'\n?```$', '', result)
        
        lines = [line.strip() for line in result.strip().split('\n') if line.strip()]
        
        print(f"   âœ… åˆ‡åˆ†å®Œæˆ")
        print(f"   ğŸ“ åˆ‡åˆ†ç‚º {len(lines)} è¡Œ")
        return lines
    
    def _step4_align_timestamps(self, subtitle_lines: list, aligned_chars: list) -> list:
        """Step 4: æ™‚é–“æˆ³å°é½Š"""
        print("â±ï¸  Step 4: Python å­—å¹•å°é½Š...")
        
        final_subtitles = []
        char_idx = 0
        total_chars = len(aligned_chars)
        
        matched_count = 0
        fallback_count = 0
        total_script_chars = sum(len(line.replace("\n", "").replace("\r", "")) for line in subtitle_lines)
        
        current_time = aligned_chars[0]["start"] if aligned_chars else 0.0
        
        for line in subtitle_lines:
            line_clean = line.replace("\n", "").replace("\r", "")
            if not line_clean:
                continue
                
            start_time = None
            end_time = None
            
            for char in line_clean:
                found = False
                search_window = 100
                
                for k in range(min(search_window, total_chars - char_idx)):
                    if aligned_chars[char_idx + k]["char"] == char:
                        found_idx = char_idx + k
                        item = aligned_chars[found_idx]
                        
                        if start_time is None:
                            start_time = item["start"]
                        
                        end_time = item["end"]
                        current_time = item["end"]
                        char_idx = found_idx + 1
                        found = True
                        matched_count += 1
                        break
                
                if not found:
                    fallback_count += 1
                    
                    if char_idx < total_chars:
                        item = aligned_chars[char_idx]
                        if start_time is None:
                            start_time = item["start"]
                        end_time = item["end"]
                        current_time = item["end"]
                        char_idx += 1
                    else:
                        if start_time is None:
                            start_time = current_time
                        end_time = current_time
            
            if start_time is not None:
                if end_time <= start_time:
                    end_time = start_time + 0.5
                
                final_subtitles.append({
                    "start": start_time,
                    "end": end_time,
                    "text": line
                })
        
        # è¦†è“‹ç‡æª¢æŸ¥
        if total_script_chars > 0:
            coverage = matched_count / total_script_chars
            print(f"   ğŸ“Š å°é½Šè¦†è“‹ç‡ï¼š{coverage:.1%} ({matched_count}/{total_script_chars} å­—å…ƒ)")
            
            if coverage < 0.8:
                print(f"   âš ï¸  è­¦å‘Šï¼šè¦†è“‹ç‡ä½æ–¼ 80%ï¼Œå­—å¹•æ™‚é–“å¯èƒ½ä¸å¤ ç²¾ç¢ºï¼")
            
            if fallback_count > 0:
                print(f"   â„¹ï¸  ä½¿ç”¨ fallback æ™‚é–“çš„å­—å…ƒæ•¸ï¼š{fallback_count}")
        
        print("   âœ… å°é½Šå®Œæˆ")
        return final_subtitles
    
    def _format_timestamp(self, seconds: float) -> str:
        """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
        millis = int((seconds % 1) * 1000)
        seconds = int(seconds)
        minutes = seconds // 60
        hours = minutes // 60
        minutes %= 60
        seconds %= 60
        return f"{hours:02}:{minutes:02}:{seconds:02},{millis:03}"
    
    def _save_srt(self, subtitles: list, output_path: Path):
        """å„²å­˜ SRT æª”æ¡ˆ"""
        with open(output_path, "w", encoding="utf-8") as f:
            for i, sub in enumerate(subtitles, 1):
                start = self._format_timestamp(sub["start"])
                end = self._format_timestamp(sub["end"])
                text = re.sub(r'[ï¼Œã€‚ã€ï¼›ï¼š,.]+$', '', sub["text"])
                f.write(f"{i}\n{start} --> {end}\n{text}\n\n")
        
        print(f"âœ… æˆåŠŸï¼å­—å¹•å·²å„²å­˜è‡³ï¼š{output_path}")
        print(f"   å…± {len(subtitles)} è¡Œå­—å¹•")
    
    def _save_debug_json(self, path: Path, data):
        """å„²å­˜é™¤éŒ¯ç”¨ JSON"""
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"   ğŸ’¾ é™¤éŒ¯çµæœå·²å„²å­˜ï¼š{path}")
    
    def _save_debug_text(self, path: Path, lines: list):
        """å„²å­˜é™¤éŒ¯ç”¨ç´”æ–‡å­—æª”ï¼ˆæ¯è¡Œä¸€æ®µï¼‰"""
        with open(path, "w", encoding="utf-8") as f:
            for line in lines:
                f.write(line + "\n")
        print(f"   ğŸ’¾ é™¤éŒ¯çµæœå·²å„²å­˜ï¼š{path}")

