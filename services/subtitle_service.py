"""
å­—å¹•ç”Ÿæˆæœå‹™
å¾ generate_subtitles.py æŠ½é›¢çš„æ ¸å¿ƒæ¥­å‹™é‚è¼¯
"""

import os
import re
import json
import difflib
import subprocess
from pathlib import Path
from opencc import OpenCC

from integrations.openai_client import get_openai_client


class SubtitleService:
    """
    å­—å¹•ç”Ÿæˆæœå‹™
    
    æµç¨‹ï¼š
    1. å¾ Avatar å½±ç‰‡æå–éŸ³è»Œ
    2. Whisper èªéŸ³è¾¨è­˜ï¼ˆå­—ç´šæ™‚é–“æˆ³ï¼‰
    3. Force Alignmentï¼ˆDTW å°é½Šä¿®æ­£éŒ¯å­—ï¼‰
    4. GPT æ™ºæ…§æ–·å¥
    5. æ™‚é–“æˆ³å°é½Šç”¢ç”Ÿ SRT
    """
    
    # æª”æ¡ˆå‘½åç´„å®š
    AVATAR_FILENAME = "avatar_full.mp4"
    EXTRACTED_AUDIO_FILENAME = "_extracted_audio.mp3"
    SCRIPT_FILENAME = "full_script.txt"
    SUBTITLE_FILENAME = "full_subtitle.srt"
    
    # GPT æ–·å¥æç¤ºè©
    SEGMENTATION_PROMPT = """ä½ æ˜¯å°ˆæ¥­çš„å­—å¹•è£½ä½œå“¡ã€‚ä½ çš„ä»»å‹™æ˜¯å°‡æ ¡æ­£å¾Œçš„æ–‡å­—åˆ‡åˆ†æˆé©åˆå­—å¹•é¡¯ç¤ºçš„æ®µè½ã€‚

## æ–·å¥é‚è¼¯ï¼ˆéå¸¸é‡è¦ï¼Œè«‹åš´æ ¼éµå®ˆï¼‰

### è¦å‰‡ 1ï¼šå°Šé‡åŸç¨¿çš„æ®µè½çµæ§‹
- åŸç¨¿ä¸­çš„æ¯ä¸€å€‹æ®µè½ï¼ˆä»¥æ›è¡Œåˆ†éš”ï¼‰æ˜¯ç¨ç«‹çš„è™•ç†å–®ä½
- æ®µè½èˆ‡æ®µè½ä¹‹é–“æ˜¯è‡ªç„¶çš„åˆ†éš”é»ï¼Œ**å¿…é ˆæ›è¡Œ**

### è¦å‰‡ 2ï¼š18 å­—åŸå‰‡ï¼ˆä¸å«æ¨™é»ï¼‰
- è¨ˆç®—å­—æ•¸æ™‚ï¼Œ**å¿½ç•¥** æ¨™é»ç¬¦è™Ÿï¼ˆï¼Œã€‚ï¼Ÿï¼ï¼šï¼›ã€Œã€ç­‰ï¼‰ï¼Œåªè¨ˆç®—**åœ‹å­—/è‹±æ–‡å­—æ¯/æ•¸å­—**
- å¦‚æœä¸€æ®µæ–‡å­—çš„**ç´”å­—æ•¸ â‰¤ 18**ï¼š**ä¿æŒå®Œæ•´ï¼Œä¸æ‹†åˆ†**
- å¦‚æœä¸€æ®µæ–‡å­—çš„**ç´”å­—æ•¸ > 18**ï¼š**å¿…é ˆæ‹†åˆ†**

### è¦å‰‡ 3ï¼šæ‹†åˆ†ç­–ç•¥
- å¦‚æœå¿…é ˆæ‹†åˆ†ï¼Œå„ªå…ˆåœ¨ **é€—è™Ÿï¼ˆï¼Œï¼‰ã€é “è™Ÿï¼ˆã€ï¼‰** å¾Œé¢æ–·é–‹
- å¦‚æœæ²’æœ‰æ¨™é»å¯æ–·ï¼Œå‰‡åœ¨è©èªé‚Šç•Œæ–·é–‹
- çµ•å°ä¸è¦åœ¨è©èªä¸­é–“æ–·é–‹

## ç¯„ä¾‹

### åŸç¨¿
```
ç•¶é¢¨åœä¸‹ä¾†çš„æ™‚å€™ï¼Œèª°æœƒæœ€å…ˆæ‰ä¸‹ä¾†æ‘”æ­»ï¼Ÿ
```
å­—æ•¸åˆ†æï¼šã€Œç•¶é¢¨åœä¸‹ä¾†çš„æ™‚å€™èª°æœƒæœ€å…ˆæ‰ä¸‹ä¾†æ‘”æ­»ã€å…± 18 å€‹åœ‹å­—ã€‚
åˆ¤æ–·ï¼šâ‰¤ 18 å­—ï¼Œä¸æ‹†åˆ†ã€‚

### è¼¸å‡º
```
ç•¶é¢¨åœä¸‹ä¾†çš„æ™‚å€™ï¼Œèª°æœƒæœ€å…ˆæ‰ä¸‹ä¾†æ‘”æ­»ï¼Ÿ
```

### åŸç¨¿
```
ä»Šå¤©è¦è·Ÿè¦ªæ„›çš„ KQ æœ‹å‹å€‘èŠçš„é€™é–“å…¬å¸ï¼Œæœ€è¿‘å¯æ˜¯ç«™åœ¨é¢¨å£ä¸Šçš„è¶…ç´šå·¨æ˜Ÿ
```
å­—æ•¸åˆ†æï¼šå…± 30+ å€‹åœ‹å­—ï¼Œè¶…é 18ï¼Œéœ€æ‹†åˆ†ã€‚

### è¼¸å‡º
```
ä»Šå¤©è¦è·Ÿè¦ªæ„›çš„ KQ æœ‹å‹å€‘èŠçš„é€™é–“å…¬å¸ï¼Œ
æœ€è¿‘å¯æ˜¯ç«™åœ¨é¢¨å£ä¸Šçš„è¶…ç´šå·¨æ˜Ÿ
```

### åŸç¨¿
```
é€™æ˜¯ä¸€å€‹ç˜‹ç‹‚çš„æ™‚ä»£ï¼Œé¢¨ä¾†äº†ï¼Œé€£è±¬éƒ½æœƒé£›ï¼Œä½†åœ¨æˆ‘å€‘é–‹å§‹ä»Šå¤©çš„è©±é¡Œä¹‹å‰ï¼Œæˆ‘æƒ³å•ä½ ä¸€å€‹å¾ˆåš´è‚…çš„å•é¡Œï¼šç•¶é¢¨åœä¸‹ä¾†çš„æ™‚å€™ï¼Œèª°æœƒæœ€å…ˆæ‰ä¸‹ä¾†æ‘”æ­»ï¼Ÿæ²’éŒ¯ï¼Œå°±æ˜¯é‚£éš»è±¬ã€‚
```
å­—æ•¸åˆ†æï¼šå…± 60+ å€‹åœ‹å­—ï¼Œé è¶… 18ï¼Œå¿…é ˆæ‹†åˆ†æˆå¤šè¡Œã€‚

### è¼¸å‡º
```
é€™æ˜¯ä¸€å€‹ç˜‹ç‹‚çš„æ™‚ä»£ï¼Œ
é¢¨ä¾†äº†ï¼Œé€£è±¬éƒ½æœƒé£›ï¼Œ
ä½†åœ¨æˆ‘å€‘é–‹å§‹ä»Šå¤©çš„è©±é¡Œä¹‹å‰ï¼Œ
æˆ‘æƒ³å•ä½ ä¸€å€‹å¾ˆåš´è‚…çš„å•é¡Œï¼š
ç•¶é¢¨åœä¸‹ä¾†çš„æ™‚å€™ï¼Œ
èª°æœƒæœ€å…ˆæ‰ä¸‹ä¾†æ‘”æ­»ï¼Ÿ
æ²’éŒ¯ï¼Œå°±æ˜¯é‚£éš»è±¬ã€‚
```

## è¼¸å‡ºæ ¼å¼
- æ¯è¡Œä¸€æ®µå­—å¹•æ–‡å­—
- ä¸è¦è¼¸å‡ºç·¨è™Ÿæˆ–æ™‚é–“æˆ³
- åªè¼¸å‡ºç´”æ–‡å­—
- ç¢ºä¿æ˜¯ç¹é«”ä¸­æ–‡"""
    
    def __init__(self):
        self.openai_client = get_openai_client()
        self.cc = OpenCC('s2t')
    
    def generate(self, folder_path: Path, debug: bool = True) -> Path:
        """
        ç”Ÿæˆå­—å¹•çš„ä¸»å…¥å£
        
        Args:
            folder_path: ç´ æè³‡æ–™å¤¾è·¯å¾‘
            debug: æ˜¯å¦å„²å­˜ä¸­é–“çµæœä¾›é™¤éŒ¯
            
        Returns:
            ç”Ÿæˆçš„ SRT æª”æ¡ˆè·¯å¾‘
        """
        folder_path = Path(folder_path)
        
        # æª”æ¡ˆè·¯å¾‘
        avatar_path = folder_path / self.AVATAR_FILENAME
        script_path = folder_path / self.SCRIPT_FILENAME
        output_path = folder_path / self.SUBTITLE_FILENAME
        extracted_audio_path = folder_path / self.EXTRACTED_AUDIO_FILENAME
        
        # é©—è­‰å¿…è¦æª”æ¡ˆ
        self._validate_files(avatar_path, script_path)
        
        print("============================================================")
        print("ğŸ™ï¸  å­—å¹•ç”Ÿæˆæœå‹™")
        print("   Avatar éŸ³è»Œæå– -> Whisper -> Force Align -> GPT -> SRT")
        print("============================================================")
        print(f"ğŸ“ å·¥ä½œç›®éŒ„ï¼š{folder_path}")
        
        try:
            # Step 0: å¾ Avatar å½±ç‰‡æå–éŸ³è»Œ
            self._extract_audio(avatar_path, extracted_audio_path)
            
            # è¼‰å…¥é€å­—ç¨¿
            full_script = self._load_script(script_path)
            print(f"ğŸ“ é€å­—ç¨¿é•·åº¦ï¼š{len(full_script)} å­—")
            
            # Step 1: Whisper èªéŸ³è¾¨è­˜
            whisper_timestamps = self._step1_transcribe_whisper(extracted_audio_path)
            
            if debug:
                self._save_debug_json(folder_path / "_debug_step1_whisper.json", whisper_timestamps)
            
            # Step 2: Force Alignment
            aligned_chars = self._step2_force_alignment(whisper_timestamps, full_script)
            
            if debug:
                self._save_debug_json(folder_path / "_debug_step2_alignment.json", aligned_chars)
            
            # Step 3: GPT æ–‡å­—åˆ‡åˆ†
            subtitle_lines = self._step3_segment_text(full_script)
            
            # Step 4: æ™‚é–“æˆ³å°é½Š
            final_subtitles = self._step4_align_timestamps(subtitle_lines, aligned_chars)
            
            # å„²å­˜ SRT
            self._save_srt(final_subtitles, output_path)
            
            print("============================================================")
            
            return output_path
            
        finally:
            # æ¸…ç†æš«å­˜çš„æå–éŸ³æª”
            if extracted_audio_path.exists():
                extracted_audio_path.unlink()
                print("   ğŸ—‘ï¸  å·²æ¸…ç†æš«å­˜éŸ³æª”")
    
    def _validate_files(self, avatar_path: Path, script_path: Path):
        """é©—è­‰å¿…è¦æª”æ¡ˆå­˜åœ¨"""
        if not avatar_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ° Avatar å½±ç‰‡ï¼š{avatar_path}")
        if not script_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°é€å­—ç¨¿ï¼š{script_path}")
    
    def _extract_audio(self, video_path: Path, output_path: Path) -> Path:
        """å¾ Avatar å½±ç‰‡æå–éŸ³è»Œ"""
        print("\nğŸ”Š å¾ Avatar å½±ç‰‡æå–éŸ³è»Œ...")
        
        result = subprocess.run([
            'ffmpeg', '-y',
            '-i', str(video_path),
            '-vn',
            '-acodec', 'libmp3lame',
            '-q:a', '2',
            str(output_path)
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âš ï¸  FFmpeg è­¦å‘Šï¼š{result.stderr[-500:] if result.stderr else 'unknown'}")
        
        print(f"   âœ… éŸ³è»Œæå–å®Œæˆï¼š{output_path}")
        return output_path
    
    def _load_script(self, script_path: Path) -> str:
        """è®€å–ä¸¦æ¨™æº–åŒ–é€å­—ç¨¿"""
        with open(script_path, "r", encoding="utf-8") as f:
            content = f.read()
        content = content.replace("\r\n", "\n").replace("\r", "\n")
        return content
    
    def _step1_transcribe_whisper(self, audio_path: Path) -> list:
        """Step 1: Whisper èªéŸ³è¾¨è­˜"""
        print("ğŸš€ é–‹å§‹ Step 1: Whisper API èªéŸ³è¾¨è­˜...")
        print("   æ­£åœ¨ä¸Šå‚³éŸ³è¨Šè‡³ OpenAI...")
        
        response = self.openai_client.transcribe_audio(audio_path)
        
        print(f"   API å›å‚³æˆåŠŸ (Duration: {response.duration:.2f}s)")
        
        word_timestamps = []
        if hasattr(response, 'words'):
            for word_obj in response.words:
                word_timestamps.append({
                    "word": self.cc.convert(word_obj.word.strip()),
                    "start": word_obj.start,
                    "end": word_obj.end
                })
        else:
            print("   âš ï¸  è­¦å‘Šï¼šAPI æœªå›å‚³è©³ç´°å­—ç´šæ™‚é–“æˆ³")
        
        print(f"   âœ… å–å¾— {len(word_timestamps)} å€‹å­—ç´šæ™‚é–“æˆ³")
        return word_timestamps
    
    def _step2_force_alignment(self, whisper_timestamps: list, full_script: str) -> list:
        """Step 2: Force Alignment (DTW å°é½Š)"""
        print("ğŸ”§ Step 2: åŸ·è¡Œ Force Alignment (æ™‚é–“æˆ³å°é½Š)...")
        
        # æº–å‚™ Whisper çš„å­—å…ƒåˆ—è¡¨
        whisper_chars = []
        for w in whisper_timestamps:
            for char in w["word"]:
                whisper_chars.append({"char": char, "start": w["start"], "end": w["end"]})
        
        # æº–å‚™ Script çš„å­—å…ƒåˆ—è¡¨
        script_chars = list(full_script.replace("\n", ""))
        
        whisper_str = "".join([x["char"] for x in whisper_chars])
        script_str = "".join(script_chars)
        
        # ä½¿ç”¨ difflib é€²è¡Œåºåˆ—æ¯”å°
        matcher = difflib.SequenceMatcher(None, whisper_str, script_str, autojunk=False)
        
        aligned_results = []
        current_time = 0.0
        if whisper_chars:
            current_time = whisper_chars[0]["start"]
        
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'equal':
                for k in range(j2 - j1):
                    w_char = whisper_chars[i1 + k]
                    aligned_results.append({
                        "char": script_str[j1 + k],
                        "start": w_char["start"],
                        "end": w_char["end"]
                    })
                    current_time = w_char["end"]
                    
            elif tag == 'replace':
                if i2 > i1:
                    start_t = whisper_chars[i1]["start"]
                    end_t = whisper_chars[i2-1]["end"]
                else:
                    start_t = current_time
                    end_t = current_time
                    
                duration = end_t - start_t
                num_script_chars = j2 - j1
                
                if num_script_chars > 0:
                    char_duration = duration / num_script_chars
                    for k in range(num_script_chars):
                        aligned_results.append({
                            "char": script_str[j1 + k],
                            "start": start_t + (k * char_duration),
                            "end": start_t + ((k + 1) * char_duration)
                        })
                current_time = end_t
                
            elif tag == 'delete':
                if i2 > i1:
                    current_time = whisper_chars[i2-1]["end"]
                
            elif tag == 'insert':
                for k in range(j2 - j1):
                    aligned_results.append({
                        "char": script_str[j1 + k],
                        "start": current_time,
                        "end": current_time
                    })
        
        print(f"   âœ… Force Alignment å®Œæˆ (å…± {len(aligned_results)} å€‹å­—å…ƒ)")
        return aligned_results
    
    def _step3_segment_text(self, transcript: str) -> list:
        """Step 3: GPT æ–‡å­—åˆ‡åˆ†"""
        print("âœ‚ï¸  Step 3: GPT æ–‡å­—åˆ‡åˆ†...")
        
        user_prompt = f"""è«‹æ ¹æ“šåŸç¨¿çš„æ®µè½çµæ§‹ï¼Œå°‡ä»¥ä¸‹æ–‡å­—åˆ‡åˆ†æˆå­—å¹•æ®µè½ï¼š

## åŸç¨¿
{transcript}

è«‹è¼¸å‡ºåˆ‡åˆ†å¾Œçš„ç´”æ–‡å­—ï¼ˆæ¯è¡Œä¸€æ®µï¼‰ã€‚"""
        
        result = self.openai_client.chat_completion(
            system_prompt=self.SEGMENTATION_PROMPT,
            user_prompt=user_prompt
        )
        
        # æ¸…ç†çµæœ
        result = re.sub(r'^```\n?', '', result)
        result = re.sub(r'\n?```$', '', result)
        
        lines = [line.strip() for line in result.strip().split('\n') if line.strip()]
        
        print(f"   âœ… åˆ‡åˆ†å®Œæˆ")
        print(f"   ğŸ“ åˆ‡åˆ†ç‚º {len(lines)} è¡Œ")
        return lines
    
    def _step4_align_timestamps(self, subtitle_lines: list, aligned_chars: list) -> list:
        """Step 4: æ™‚é–“æˆ³å°é½Š"""
        print("â±ï¸  Step 4: Python å­—å¹•å°é½Š...")
        
        final_subtitles = []
        char_idx = 0
        total_chars = len(aligned_chars)
        
        matched_count = 0
        fallback_count = 0
        total_script_chars = sum(len(line.replace("\n", "").replace("\r", "")) for line in subtitle_lines)
        
        current_time = aligned_chars[0]["start"] if aligned_chars else 0.0
        
        for line in subtitle_lines:
            line_clean = line.replace("\n", "").replace("\r", "")
            if not line_clean:
                continue
                
            start_time = None
            end_time = None
            
            for char in line_clean:
                found = False
                search_window = 100
                
                for k in range(min(search_window, total_chars - char_idx)):
                    if aligned_chars[char_idx + k]["char"] == char:
                        found_idx = char_idx + k
                        item = aligned_chars[found_idx]
                        
                        if start_time is None:
                            start_time = item["start"]
                        
                        end_time = item["end"]
                        current_time = item["end"]
                        char_idx = found_idx + 1
                        found = True
                        matched_count += 1
                        break
                
                if not found:
                    fallback_count += 1
                    
                    if char_idx < total_chars:
                        item = aligned_chars[char_idx]
                        if start_time is None:
                            start_time = item["start"]
                        end_time = item["end"]
                        current_time = item["end"]
                        char_idx += 1
                    else:
                        if start_time is None:
                            start_time = current_time
                        end_time = current_time
            
            if start_time is not None:
                if end_time <= start_time:
                    end_time = start_time + 0.5
                
                final_subtitles.append({
                    "start": start_time,
                    "end": end_time,
                    "text": line
                })
        
        # è¦†è“‹ç‡æª¢æŸ¥
        if total_script_chars > 0:
            coverage = matched_count / total_script_chars
            print(f"   ğŸ“Š å°é½Šè¦†è“‹ç‡ï¼š{coverage:.1%} ({matched_count}/{total_script_chars} å­—å…ƒ)")
            
            if coverage < 0.8:
                print(f"   âš ï¸  è­¦å‘Šï¼šè¦†è“‹ç‡ä½æ–¼ 80%ï¼Œå­—å¹•æ™‚é–“å¯èƒ½ä¸å¤ ç²¾ç¢ºï¼")
            
            if fallback_count > 0:
                print(f"   â„¹ï¸  ä½¿ç”¨ fallback æ™‚é–“çš„å­—å…ƒæ•¸ï¼š{fallback_count}")
        
        print("   âœ… å°é½Šå®Œæˆ")
        return final_subtitles
    
    def _format_timestamp(self, seconds: float) -> str:
        """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
        millis = int((seconds % 1) * 1000)
        seconds = int(seconds)
        minutes = seconds // 60
        hours = minutes // 60
        minutes %= 60
        seconds %= 60
        return f"{hours:02}:{minutes:02}:{seconds:02},{millis:03}"
    
    def _save_srt(self, subtitles: list, output_path: Path):
        """å„²å­˜ SRT æª”æ¡ˆ"""
        with open(output_path, "w", encoding="utf-8") as f:
            for i, sub in enumerate(subtitles, 1):
                start = self._format_timestamp(sub["start"])
                end = self._format_timestamp(sub["end"])
                text = re.sub(r'[ï¼Œã€‚ã€ï¼›ï¼š,.]+$', '', sub["text"])
                f.write(f"{i}\n{start} --> {end}\n{text}\n\n")
        
        print(f"âœ… æˆåŠŸï¼å­—å¹•å·²å„²å­˜è‡³ï¼š{output_path}")
        print(f"   å…± {len(subtitles)} è¡Œå­—å¹•")
    
    def _save_debug_json(self, path: Path, data):
        """å„²å­˜é™¤éŒ¯ç”¨ JSON"""
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"   ğŸ’¾ é™¤éŒ¯çµæœå·²å„²å­˜ï¼š{path}")
